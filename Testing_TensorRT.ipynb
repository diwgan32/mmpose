{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0045fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "from mmcv.tensorrt import (TRTWrapper, onnx2trt, save_trt_engine,\n",
    "                                   is_tensorrt_plugin_loaded)\n",
    "\n",
    "assert is_tensorrt_plugin_loaded(), 'Requires to complie TensorRT plugins in mmcv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195f7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file = 'hrnet.onnx'\n",
    "trt_file = 'hrnet.trt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "841fc529",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(onnx_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37b28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HRNet [1, 3, 256, 192]\n",
    "opt_shape_dict = {\n",
    "    'img': [[1, 3, 256, 192],\n",
    "           [1, 3, 256, 192],\n",
    "           [4, 3, 256, 192]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1331eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TensorRT] INFO: Detected 1 inputs and 1 output network tensors.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "max_workspace_size = 1 << 30\n",
    "trt_engine = onnx2trt(\n",
    "    onnx_model,\n",
    "    opt_shape_dict,\n",
    "    log_level=trt.Logger.INFO,\n",
    "    max_workspace_size=max_workspace_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da3af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trt_engine(trt_engine, trt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c0a4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_model = TRTWrapper(trt_file, ['input.1'], ['116'])\n",
    "trt_model = trt_model.to(torch.device(\"cuda:1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "encouraging-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in trt_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from mmpose.core.evaluation.top_down_eval import keypoints_from_heatmaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"3d_img.p\", \"rb\")\n",
    "batch_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "with torch.no_grad():\n",
    "    trt_outputs = trt_model({'input.1': batch_data[\"input\"][0][None, :]})\n",
    "    output = trt_outputs['116']\n",
    "    poses_3d = output.cpu().detach().numpy()\n",
    "    \n",
    "    if poses_3d.shape[-1] != 4:\n",
    "        assert poses_3d.shape[-1] == 3\n",
    "        dummy_score = np.ones(\n",
    "            poses_3d.shape[:-1] + (1, ), dtype=poses_3d.dtype)\n",
    "        poses_3d = np.concatenate((poses_3d, dummy_score), axis=-1)\n",
    "    pose_results = []\n",
    "    for pose_2d, pose_3d in zip(pose_sequences_2d, poses_3d):\n",
    "        pose_result = pose_2d.copy()\n",
    "        pose_result['keypoints_3d'] = pose_3d\n",
    "        pose_results.append(pose_result)\n",
    "        \n",
    "    print(output_np)\n",
    "print(f\"Time: {time.time() - t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_2d = keypoints[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread(\"test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390edfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keypoints(img, keypoints):\n",
    "    for i in range(17):\n",
    "        img = cv2.circle(img, (int(keypoints[i][0]), int(keypoints[i][1])), 3, (255, 0, 0), 1)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f91f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = show_keypoints(img, keypoints_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30fc4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a77d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = trt_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in device:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f8a85",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import inference_detector\n",
    "from mmdet2trt.apis import create_wrap_detector\n",
    "from mmcv.tensorrt import (TRTWrapper, onnx2trt, save_trt_engine,\n",
    "                                   is_tensorrt_plugin_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_detector = create_wrap_detector(\"faster_rcnn.trt\", \"demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py\", \"cuda:0\")\n",
    "\n",
    "\n",
    "# result share same format as mmdetection\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2511851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "frame = cv2.imread(\"test.jpg\")\n",
    "print(\"Read frame\")\n",
    "print(frame)\n",
    "print(next(trt_detector.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_detector(trt_detector, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6765d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3247e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
