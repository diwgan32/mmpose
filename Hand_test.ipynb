{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116c6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pre = {\n",
    "    'det_config': 'demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py',\n",
    "    'det_checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth',\n",
    "    'hand_detector_config': 'configs/hand/2d_kpt_sview_rgb_img/topdown_heatmap/coco_wholebody_hand/hrnetv2_w18_coco_wholebody_hand_256x256.py',\n",
    "    'hand_detector_checkpoint': 'https://download.openmmlab.com/mmpose/hand/hrnetv2/hrnetv2_w18_coco_wholebody_hand_256x256-1c028db7_20210908.pth',\n",
    "    'pose_detector_config': 'configs/wholebody/2d_kpt_sview_rgb_img/topdown_heatmap/coco-wholebody/hrnet_w48_coco_wholebody_256x192.py',\n",
    "    'pose_detector_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_wholebody_256x192-643e18cb_20200922.pth',\n",
    "    'hand_lifter_config': 'configs/hand/3d_kpt_sview_rgb_vid/hand_pose_lift/handpose3d_dex_27frames_fullconv_supervised.py',\n",
    "    'hand_lifter_checkpoint': '/home/ubuntu/PoseEstimation/mmpose/tools/work_dirs/handpose3d_dex_27frames_fullconv_supervised/epoch_80.pth',\n",
    "    # Flags/Optional\n",
    "    # 'video_path': 'demo/resources/jeldwen-1.mp4',\n",
    "    'rebase_keypoint_height': True,\n",
    "    'norm_pose_2d': None,\n",
    "    'num_instances': -1,\n",
    "    'show': False,\n",
    "    'out_video_root': 'vis_results',\n",
    "    'device': 'cuda:0',\n",
    "    'det_cat_id': 1,\n",
    "    'bbox_thr': 0.9,\n",
    "    'kpt_thr': 0.3,\n",
    "    'use_oks_tracking': None,\n",
    "    'tracking_thr': 0.3,\n",
    "    'euro': None,\n",
    "    'radius': 8,\n",
    "    'thickness': 2,\n",
    "}\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(**args_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f78451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mmpose.core.visualization import imshow_bboxes, imshow_keypoints\n",
    "from mmpose.apis import (extract_pose_sequence, get_track_id,\n",
    "                         inference_pose_lifter_model,\n",
    "                         inference_top_down_pose_model, init_pose_model,\n",
    "                         process_mmdet_results, vis_3d_pose_result)\n",
    "\n",
    "try:\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "\n",
    "    has_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    has_mmdet = False\n",
    "    \n",
    "from demo import zach_v_body3d_two_stage_video as m_2d_3d_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9a0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LWRIST_IDX = 9\n",
    "RWRIST_IDX = 10\n",
    "\n",
    "skeleton = [[0, 1], [1, 2], [2, 3], [3, 4], \n",
    "            [0, 5], [5, 6], [6, 7], [7, 8], \n",
    "            [0, 9], [9, 10], [10, 11], [11, 12], \n",
    "            [0, 13], [13, 14], [14, 15], [15, 16], \n",
    "            [0, 17], [17, 18], [18, 19], [19, 20]\n",
    "           ]\n",
    "\n",
    "def create_writer(frame, args, fps):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(\n",
    "        osp.join(args.out_video_root, f'tumeke_testing/vis_hands_2d_{osp.basename(args.file_path)}'),\n",
    "        fourcc,\n",
    "        fps,\n",
    "        (frame.shape[1], frame.shape[0])\n",
    "    )\n",
    "    return writer\n",
    "\n",
    "def process_image_hands(args, img_path):\n",
    "    frame_idx = 0\n",
    "    frame = cv2.imread(img_path)\n",
    "\n",
    "    pose_det_model = init_pose_model(\n",
    "        args.pose_detector_config,\n",
    "        args.pose_detector_checkpoint,\n",
    "        device=args.device.lower()\n",
    "    )\n",
    "    \n",
    "    pose_det_results, _ = inference_top_down_pose_model(\n",
    "        pose_det_model,\n",
    "        frame,\n",
    "        None,\n",
    "        bbox_thr=None,\n",
    "        format='xyxy',\n",
    "        dataset=None,\n",
    "        return_heatmap=False,\n",
    "        outputs=None\n",
    "    )\n",
    "    rendered = imshow_keypoints(frame, np.expand_dims(pose_det_results[0][\"keypoints\"], 0), pose_kpt_color=[(255, 0, 0)]*21)\n",
    "    plt.imshow(rendered)\n",
    "    plt.show()\n",
    "    print(pose_det_results)\n",
    "\n",
    "def process_video_hands(args):\n",
    "    frame_idx = 0\n",
    "    assert has_mmdet, 'Please install mmdet to run the demo.'\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "    assert args.show or (args.out_video_root != '')\n",
    "    assert args.det_config is not None\n",
    "    assert args.det_checkpoint is not None\n",
    "\n",
    "    video = mmcv.VideoReader(args.file_path)\n",
    "    assert video.opened, f'Failed to load video file {args.file_path}'\n",
    "\n",
    "    # First stage: 2D pose detection\n",
    "    print('Stage #1: 2D pose detection.')\n",
    "    \n",
    "    if args.out_video_root == '':\n",
    "        save_out_video = False\n",
    "    else:\n",
    "        os.makedirs(args.out_video_root, exist_ok=True)\n",
    "        save_out_video = True\n",
    "\n",
    "    if save_out_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        fps = video.fps\n",
    "        writer = None\n",
    "        \n",
    "    person_det_model = init_detector(\n",
    "        args.det_config, args.det_checkpoint, device=args.device.lower()\n",
    "    )\n",
    "\n",
    "    pose_det_model = init_pose_model(\n",
    "        args.pose_detector_config,\n",
    "        args.pose_detector_checkpoint,\n",
    "        device=args.device.lower()\n",
    "    )\n",
    "    \n",
    "    hand_det_model = init_pose_model(\n",
    "        args.hand_detector_config,\n",
    "        args.hand_detector_checkpoint,\n",
    "        device=args.device.lower()\n",
    "    )\n",
    "    should_render_2d = True\n",
    "    print(\"Initialized Model\")\n",
    "    \n",
    "    num_instances = args.num_instances\n",
    "    pose_det_dataset = pose_det_model.cfg.data['test']['type']\n",
    "    pose_det_results_list = []\n",
    "    hand_det_results_list = []\n",
    "    writer = None\n",
    "    if (args.detections_hand_2d == \"\"):\n",
    "        for frame in video:\n",
    "            t = time.time()\n",
    "            mmdet_results = inference_detector(person_det_model, frame)\n",
    "\n",
    "            # keep the person class bounding boxes.\n",
    "            person_det_results = process_mmdet_results(mmdet_results,\n",
    "                                                       args.det_cat_id)\n",
    "\n",
    "            pose_det_results, _ = inference_top_down_pose_model(\n",
    "                pose_det_model,\n",
    "                frame,\n",
    "                person_det_results,\n",
    "                bbox_thr=args.bbox_thr,\n",
    "                format='xyxy',\n",
    "                dataset=pose_det_dataset,\n",
    "                return_heatmap=False,\n",
    "                outputs=None)\n",
    "\n",
    "            if (should_render_2d):\n",
    "                if (len(pose_det_results) == 0):\n",
    "                    if (writer is None):\n",
    "                        writer = create_writer(frame, args, video.fps)\n",
    "                    writer.write(frame)\n",
    "                    continue\n",
    "            right_hand = pose_det_results[0][\"keypoints\"][112:112+21]\n",
    "            #print(right_hand.shape, np.max(right_hand[:, 0]) + 10, frame.shape[1])\n",
    "            x_min = int(max(np.min(right_hand[:, 0]) - 30, 0))\n",
    "            x_max = int(min(np.max(right_hand[:, 0]) + 30, frame.shape[1]))\n",
    "            y_min = int(max(np.min(right_hand[:, 1]) - 30, 0))\n",
    "            y_max = int(min(np.max(right_hand[:, 1]) + 30, frame.shape[0]))\n",
    "            \n",
    "            left_hand = pose_det_results[0][\"keypoints\"][91:91+21]\n",
    "            x_min_l = int(max(np.min(left_hand[:, 0]) - 30, 0))\n",
    "            x_max_l = int(min(np.max(left_hand[:, 0]) + 30, frame.shape[1]))\n",
    "            y_min_l = int(max(np.min(left_hand[:, 1]) - 30, 0))\n",
    "            y_max_l = int(min(np.max(left_hand[:, 1]) + 30, frame.shape[0]))\n",
    "    \n",
    "            #hand_results = [{'bbox': np.array([x_min, y_min, bbox_size, bbox_size, 1.0])}]\n",
    "\n",
    "            hand_det_results_r, _ = inference_top_down_pose_model(\n",
    "                hand_det_model,\n",
    "                frame[y_min:y_max, x_min:x_max],\n",
    "                None,\n",
    "                bbox_thr=None,\n",
    "                format='xyxy',\n",
    "                dataset=pose_det_dataset,\n",
    "                return_heatmap=False,\n",
    "                outputs=None)\n",
    "\n",
    "            hand_det_results_l, _ = inference_top_down_pose_model(\n",
    "                hand_det_model,\n",
    "                frame[y_min_l:y_max_l, x_min_l:x_max_l],\n",
    "                None,\n",
    "                bbox_thr=None,\n",
    "                format='xyxy',\n",
    "                dataset=pose_det_dataset,\n",
    "                return_heatmap=False,\n",
    "                outputs=None)\n",
    "            \n",
    "            if (len(hand_det_results_l) > 1):\n",
    "                print(\"More than 1 hand detected\")\n",
    "            if (should_render_2d):\n",
    "                rendered = imshow_keypoints(\n",
    "                    frame[y_min:y_max, x_min:x_max],\n",
    "                    np.expand_dims(hand_det_results_r[0][\"keypoints\"], 0),\n",
    "                    pose_kpt_color=[(0, 0, 255)]*21,\n",
    "                    radius=4,\n",
    "                    skeleton=skeleton,\n",
    "                    pose_link_color=[(0, 0, 0)]*20\n",
    "                )\n",
    "                rendered_l = imshow_keypoints(\n",
    "                    frame[y_min_l:y_max_l, x_min_l:x_max_l],\n",
    "                    np.expand_dims(hand_det_results_l[0][\"keypoints\"], 0),\n",
    "                    pose_kpt_color=[(0, 0, 255)]*21,\n",
    "                    radius=4,\n",
    "                    skeleton=skeleton,\n",
    "                    pose_link_color=[(0, 0, 0)]*20\n",
    "                )\n",
    "                frame[y_min:y_max, x_min:x_max] = rendered\n",
    "                frame[y_min_l:y_max_l, x_min_l:x_max_l] = rendered_l\n",
    "                frame = cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (255, 0, 0), 3)\n",
    "                frame = cv2.rectangle(frame, (int(x_min_l), int(y_min_l)), (int(x_max_l), int(y_max_l)), (255, 0, 0), 3)\n",
    "                \n",
    "                if (writer is None):\n",
    "                    writer = create_writer(frame, args, video.fps)\n",
    "                writer.write(frame)\n",
    "                \n",
    "            hand_det_results_r[0][\"keypoints\"][:, 0] += x_min\n",
    "            hand_det_results_r[0][\"keypoints\"][:, 1] += y_min\n",
    "            hand_det_results_l[0][\"keypoints\"][:, 0] += x_min_l\n",
    "            hand_det_results_l[0][\"keypoints\"][:, 1] += y_min_l\n",
    "\n",
    "            \n",
    "            pose_det_results[0][\"keypoints\"][112:112+21] = hand_det_results_r[0][\"keypoints\"]\n",
    "            pose_det_results[0][\"keypoints\"][91:91+21] = hand_det_results_l[0][\"keypoints\"]\n",
    "            \n",
    "            hand_det_results_list.append(pose_det_results)\n",
    "            if (frame_idx % 100 == 0): print(f\"Idx: {frame_idx}, len: {len(video)}\")\n",
    "            frame_idx += 1\n",
    "        with open(f'work_dirs/tumeke_testing/pickle_files/{args.video_name}_hands.p', 'wb') as outfile:\n",
    "            pickle.dump(hand_det_results_list, outfile)\n",
    "    else:\n",
    "        with open(args.detections_hand_2d, 'rb') as f:\n",
    "            hand_det_results_list = pickle.load(f)\n",
    "                \n",
    "    if (should_render_2d): writer.release()\n",
    "    \n",
    "    hand_lift_model = init_pose_model(\n",
    "        args.hand_lifter_config,\n",
    "        args.hand_lifter_checkpoint,\n",
    "        device=args.device.lower())\n",
    "    \n",
    "    hand_lift_dataset = hand_lift_model.cfg.data['test']['type']\n",
    "#    writer.release()\n",
    "    # load temporal padding config from model.data_cfg\n",
    "#     if hasattr(hand_lift_model.cfg, 'test_data_cfg'):\n",
    "#         data_cfg = hand_lift_model.cfg.test_data_cfg\n",
    "#     else:\n",
    "#         data_cfg = hand_lift_model.cfg.data_cfg\n",
    "    \n",
    "#     if (isinstance(data_cfg, list)):\n",
    "#         data_cfg = data_cfg[0]\n",
    "\n",
    "#     for i, hand_det_results in enumerate(\n",
    "#             mmcv.track_iter_progress(hand_det_results_list)):\n",
    "#         # extract and pad input pose2d sequence\n",
    "#         hands_results_2d = extract_pose_sequence(\n",
    "#             hand_det_results_list,\n",
    "#             frame_idx=i,\n",
    "#             causal=data_cfg.causal,\n",
    "#             seq_len=data_cfg.seq_len,\n",
    "#             step=data_cfg.seq_frame_interval)\n",
    "#         print(\"Len\", len(hands_results_2d))\n",
    "#         # 2D-to-3D pose lifting\n",
    "#         hand_lift_results = inference_pose_lifter_model(\n",
    "#             hand_lift_model,\n",
    "#             pose_results_2d=hands_results_2d,\n",
    "#             dataset=hand_lift_dataset,\n",
    "#             with_track_id=False,\n",
    "#             image_size=video.resolution,\n",
    "#             norm_pose_2d=args.norm_pose_2d,\n",
    "#             output_num=i,\n",
    "#             dataset_info=hand_lift_model.cfg.dataset_info\n",
    "#         )\n",
    "        \n",
    "#         # Pose processing\n",
    "#         hand_lift_results_vis = []\n",
    "#         for idx, res in enumerate(hand_lift_results):\n",
    "#             keypoints_3d = res['keypoints_3d']\n",
    "#             # exchange y,z-axis, and then reverse the direction of x,z-axis\n",
    "#             keypoints_3d = keypoints_3d[..., [0, 2, 1]]\n",
    "#             keypoints_3d[..., 0] = -keypoints_3d[..., 0]\n",
    "#             keypoints_3d[..., 2] = -keypoints_3d[..., 2]\n",
    "#             # rebase height (z-axis)\n",
    "#             if args.rebase_keypoint_height:\n",
    "#                 keypoints_3d[..., 2] -= np.min(\n",
    "#                     keypoints_3d[..., 2], axis=-1, keepdims=True)\n",
    "#             res['keypoints_3d'] = keypoints_3d\n",
    "#             # add title\n",
    "#             det_res = hand_det_results[idx]\n",
    "#             res['title'] = f'Prediction ({idx})'\n",
    "#             # only visualize the target frame\n",
    "#             res['keypoints'] = det_res['keypoints']\n",
    "#             res['bbox'] = det_res['bbox']\n",
    "#             hand_lift_results_vis.append(res)\n",
    "\n",
    "#         # Visualization\n",
    "#         if num_instances < 0:\n",
    "#             num_instances = len(hand_lift_results_vis)\n",
    "#         img_vis = vis_3d_pose_result(\n",
    "#             hand_lift_model,\n",
    "#             result=hand_lift_results_vis,\n",
    "#             img=video[i],\n",
    "#             out_file=None,\n",
    "#             radius=args.radius,\n",
    "#             thickness=args.thickness,\n",
    "#             num_instances=num_instances,\n",
    "#         dataset=hand_lift_dataset)\n",
    "        \n",
    "#         if save_out_video:\n",
    "#             if writer is None:\n",
    "#                 writer = cv2.VideoWriter(\n",
    "#                     osp.join(args.out_video_root,\n",
    "#                              f'tumeke_testing/vis_hands_3d_{osp.basename(args.file_path)}'), fourcc,\n",
    "#                     fps, (img_vis.shape[1], img_vis.shape[0]))\n",
    "#             writer.write(img_vis)\n",
    "    \n",
    "    if save_out_video:\n",
    "        writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b67046c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage #1: 2D pose detection.\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_wholebody_256x192-643e18cb_20200922.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/hand/hrnetv2/hrnetv2_w18_coco_wholebody_hand_256x256-1c028db7_20210908.pth\n",
      "Initialized Model\n",
      "Idx: 0, len: 836\n",
      "Idx: 100, len: 836\n",
      "Idx: 200, len: 836\n",
      "Idx: 300, len: 836\n",
      "Idx: 400, len: 836\n",
      "Idx: 500, len: 836\n",
      "Idx: 600, len: 836\n",
      "Idx: 700, len: 836\n",
      "Idx: 800, len: 836\n",
      "load checkpoint from local path: /home/ubuntu/PoseEstimation/mmpose/tools/work_dirs/handpose3d_dex_27frames_fullconv_supervised/epoch_80.pth\n"
     ]
    }
   ],
   "source": [
    "args.video_name = 'wrist_rom'\n",
    "args.file_path = 'demo/resources/test_vids/wrist_rom.mp4'\n",
    "args.detections_2d = ''\n",
    "args.detections_hand_2d = ''\n",
    "process_video_hands(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f143ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9faec1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_cuda10)",
   "language": "python",
   "name": "conda_pytorch_cuda10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
