{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pre = {\n",
    "    'det_config': 'demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py',\n",
    "    'det_checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth',\n",
    "    'pose_detector_config': 'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py',\n",
    "    'pose_detector_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth',\n",
    "    'pose_lifter_config': 'configs/body/3d_kpt_sview_rgb_vid/video_pose_lift/h36m/videopose3d_h36m_243frames_fullconv_supervised.py',\n",
    "    'pose_lifter_checkpoint': '/home/ubuntu/epoch_80.pth',\n",
    "    # Flags/Optional\n",
    "#     'video_path': 'demo/resources/jeldwen-1.mp4',\n",
    "    'rebase_keypoint_height': True,\n",
    "    'norm_pose_2d': None,\n",
    "    'num_instances': -1,\n",
    "    'show': False,\n",
    "    'out_video_root': 'vis_results',\n",
    "    'device': 'cuda:0',\n",
    "    'det_cat_id': 1,\n",
    "    'bbox_thr': 0.9,\n",
    "    'kpt_thr': 0.3,\n",
    "    'use_oks_tracking': None,\n",
    "    'tracking_thr': 0.3,\n",
    "    'euro': None,\n",
    "    'radius': 8,\n",
    "    'thickness': 2,\n",
    "    'detections_2d': ''\n",
    "}\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(**args_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo import zach_v_body3d_two_stage_video as m_2d_3d_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one video\n",
    "import time\n",
    "args.video_name = 'BAR-S_water_ballon'\n",
    "args.file_path = 'demo/resources/test_vids/BAR-S_water_ballon.mov'\n",
    "args.detections_2d = \"\"\n",
    "# args.file_path = 'demo/resources/test_vids/gHO_sBM_c08_d20_mHO0_ch10.mp4'\n",
    "t1 = time.time()\n",
    "m_2d_3d_model.process_video(args)\n",
    "print(f\"Total time: {time.time() - t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "video_directory = 'evaluation_vids'\n",
    "\n",
    "def get_video_list():\n",
    "    '''Get list of videos to process'''\n",
    "    file_paths = glob.glob(\"demo/resources/{}/*\".format(video_directory))\n",
    "    video_names = []\n",
    "    \n",
    "    for path in file_paths:\n",
    "        video_names.append(\n",
    "            SimpleNamespace(\n",
    "                **{\n",
    "                    'video_name': re.search('/.*/.*/(.*)(?:[.])', path).group(1),\n",
    "                    'file_path': 'demo/resources/{}/'.format(video_directory) + re.search('/.*/.*/(.*)', path).group(1)\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return video_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos():\n",
    "    '''Iterate through videos and process'''\n",
    "    video_list = get_video_list()\n",
    "    print(video_list)\n",
    "    for video in video_list:\n",
    "        args.video_name = video.video_name\n",
    "        args.file_path = video.file_path\n",
    "        m_2d_3d_model.process_video(args)\n",
    "        \n",
    "process_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c1077",
   "metadata": {},
   "source": [
    "# Loading wrnch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478cb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "filename = 'work_dirs/tumeke_testing/wrnch_jsons/AFG_subject_switching_close_nurses_subjects1_partial.json'\n",
    "f = open(filename, \"r\")\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b075103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrnch_raw_data():\n",
    "    standard_format_data = []\n",
    "    wrnch_to_hrnet = [16, 19, 17, 20, 18, 13, 12, 14, 11, 15, 10, 3, 2, 4, 1, 5, 0]\n",
    "    frame_width = 720 # Update AUTOMATICALLY!\n",
    "    frame_height = 1280 # Update AUTOMATICALLY!\n",
    "    for i in range(len(data[\"frames\"])):\n",
    "        wrnch_frame = data[\"frames\"][i]\n",
    "        single_frame = []\n",
    "        for single_person_data in wrnch_frame[\"persons\"]:\n",
    "            if (\"pose2d\" not in single_person_data):\n",
    "                continue\n",
    "            if (\"joints\" not in single_person_data[\"pose2d\"]):\n",
    "                continue\n",
    "            arr_2d = single_person_data[\"pose2d\"][\"joints\"]\n",
    "            if (arr_2d == []):\n",
    "                continue\n",
    "            kpts2d = np.array(arr_2d).reshape((25, 2))\n",
    "            kpts2d[:, 0] *= frame_width\n",
    "            kpts2d[:, 1] *= frame_height\n",
    "            kpts2d = np.where(kpts2d < 0, 0, kpts2d)\n",
    "\n",
    "            standard_format = np.hstack((kpts2d[wrnch_to_hrnet], np.ones((17, 1))))\n",
    "            single_frame.append({\n",
    "                \"keypoints\": standard_format\n",
    "            })\n",
    "        standard_format_data.append(single_frame)\n",
    "    \n",
    "    return standard_format_data\n",
    "\n",
    "wrnch_raw_data = get_wrnch_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrnch_raw_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrnch_df = raw_data_to_dataframe(wrnch_raw_data)\n",
    "wrnch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893b12b",
   "metadata": {},
   "source": [
    "# Load Hrnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading pickeled keypoints\n",
    "import pickle\n",
    "with open ('work_dirs/tumeke_testing/pickle_files/AFG_subject_switching_close_nurses_subjects1_partial.p', 'rb') as fp:\n",
    "    raw_data = pickle.load(fp)\n",
    "\n",
    "'''Load picked data into numpy.\n",
    "    \n",
    "Bounding box values are: 'xyxy' = (left, top, right, bottom)\n",
    "\n",
    "Key Point values are: (ndarray[Kx3]): x, y, score\n",
    "\n",
    "'''    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just focus on videos with one subject for now\n",
    "\n",
    "raw_data[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89807934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_shoulder_i = joint_order.index('right_shoulder')\n",
    "# r_elbow_i = joint_order.index('right_elbow')\n",
    "# l_shoulder_i = joint_order.index('left_shoulder')\n",
    "# l_elbow_i = joint_order.index('left_elbow')\n",
    "\n",
    "# keypoint_array = raw_data[2][0]['keypoints']\n",
    "# keypoint_array[r_shoulder_i], keypoint_array[r_elbow_i]\n",
    "# # euclidean_dist(np.array([483.336, 456.679]), np.array([470.485, 504.871])) # 49.876016931988474\n",
    "# euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_elbow_i]) # 49.876083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_shoulder_i = joint_order.index('right_shoulder')\n",
    "# r_elbow_i = joint_order.index('right_elbow')\n",
    "# r_hip_i= joint_order.index('right_hip')\n",
    "# l_shoulder_i = joint_order.index('left_shoulder')\n",
    "# l_elbow_i = joint_order.index('left_elbow')\n",
    "# l_hip_i = joint_order.index('left_hip')\n",
    "\n",
    "# for subject in raw_data[906]:\n",
    "#     print(subject)\n",
    "#     keypoint_array = subject['keypoints']\n",
    "#     r_se_ed = euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_elbow_i])\n",
    "#     r_sh_ed = euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_hip_i])\n",
    "#     l_se_ed = euclidean_dist(keypoint_array[l_shoulder_i], keypoint_array[l_elbow_i])\n",
    "#     l_sh_ed = euclidean_dist(keypoint_array[l_shoulder_i], keypoint_array[l_hip_i])\n",
    "#     print(np.array([r_se_ed, r_sh_ed, l_se_ed, l_sh_ed]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081935ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SORT\n",
    "# sorted_raw_data = []\n",
    "# for frame in raw_data:\n",
    "#     sorted_raw_data.append(sorted(frame, key=lambda x: closest_subject_heuristic(x['keypoints']), reverse=True))\n",
    "    \n",
    "# print(sorted_raw_data[906])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram of subjects per frame\n",
    "# subjects = [len(i) for i in raw_data]\n",
    "# plt.hist(subjects, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "joint_order = [\n",
    "    \"nose\", \n",
    "    \"left_eye\", \n",
    "    \"right_eye\", \n",
    "    \"left_ear\", \n",
    "    \"right_ear\", \n",
    "    \"left_shoulder\", \n",
    "    \"right_shoulder\", \n",
    "    \"left_elbow\", \n",
    "    \"right_elbow\", \n",
    "    \"left_wrist\", \n",
    "    \"right_wrist\", \n",
    "    \"left_hip\", \n",
    "    \"right_hip\", \n",
    "    \"left_knee\", \n",
    "    \"right_knee\", \n",
    "    \"left_ankle\", \n",
    "    \"right_ankle\" \n",
    "]\n",
    "\n",
    "# def index_of(val, in_list):\n",
    "#     try:\n",
    "#         return in_list.index(val)\n",
    "#     except ValueError:\n",
    "#         return -1 \n",
    "\n",
    "# # initializing points in\n",
    "# # numpy arrays\n",
    "# point1 = np.array((1, 2))\n",
    "# point2 = np.array((2, 4))\n",
    " \n",
    "# # calculating Euclidean distance\n",
    "# # using linalg.norm()\n",
    "# dist = np.linalg.norm(point1 - point2)\n",
    "# dist\n",
    "\n",
    "def euclidean_dist(p1, p2):\n",
    "    # Euclidean distance\n",
    "    return np.linalg.norm(p1 - p2)\n",
    "\n",
    "def closest_subject_heuristic(keypoint_array):\n",
    "    '''Get avg euclidean distance between right shoulder/elbow, left shoulder/elbow, right shoulder/hip and left shoulder/hip''' \n",
    "    r_shoulder_i = joint_order.index('right_shoulder')\n",
    "    r_elbow_i = joint_order.index('right_elbow')\n",
    "    r_hip_i= joint_order.index('right_hip')\n",
    "    l_shoulder_i = joint_order.index('left_shoulder')\n",
    "    l_elbow_i = joint_order.index('left_elbow')\n",
    "    l_hip_i = joint_order.index('left_hip')\n",
    "    \n",
    "    r_se_ed = euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_elbow_i])\n",
    "    r_sh_ed = euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_hip_i])\n",
    "    l_se_ed = euclidean_dist(keypoint_array[l_shoulder_i], keypoint_array[l_elbow_i])\n",
    "    l_sh_ed = euclidean_dist(keypoint_array[l_shoulder_i], keypoint_array[l_hip_i])\n",
    "    return np.array([r_se_ed, r_sh_ed, l_se_ed, l_sh_ed]).mean()\n",
    "\n",
    "def pull_from_dict(key, dict):\n",
    "    try:\n",
    "        return dict[key]\n",
    "    except (KeyError, TypeError):\n",
    "        if key == 'bbox':\n",
    "            return np.full(5,np.NaN)\n",
    "        else:\n",
    "            return np.NaN\n",
    "\n",
    "def extract_subject(subject_num, subjects):\n",
    "    try:\n",
    "        return subjects[subject_num-1]\n",
    "    except IndexError:\n",
    "        return None \n",
    "\n",
    "def raw_data_to_dataframe(raw_data):\n",
    "    \"\"\" Load into dataframe\"\"\"\n",
    "    \n",
    "    # Order subjects in each frame by bbox size\n",
    "    sorted_raw_data = []\n",
    "    for frame in raw_data:\n",
    "        sorted_raw_data.append(sorted(frame, key=lambda x: closest_subject_heuristic(x['keypoints']), reverse=True))\n",
    "\n",
    "    # Get first identified subject in every frame\n",
    "    first_subj = np.array([extract_subject(1, i) for i in sorted_raw_data])\n",
    "\n",
    "    # Extract relevant fields to be set as columns\n",
    "    bbox = np.array([pull_from_dict('bbox', i) for i in first_subj])\n",
    "    area = np.array([pull_from_dict('area', i) for i in first_subj])\n",
    "    track_id = np.array([pull_from_dict('track_id', i) for i in first_subj])\n",
    "\n",
    "    # Structure Keypoints\n",
    "    keypoints_array = []\n",
    "    for frame in first_subj:\n",
    "        \n",
    "        #TODO(znoland):sanity check this and make sure no issues!\n",
    "        # Keypoint order! - configs/_base_/datasets/h36m.py\n",
    "        if not frame:\n",
    "            # If no data for subject\n",
    "            frame_keypoints = {}\n",
    "            for index in range(17):\n",
    "                frame_keypoints['j{}_x'.format(index)] = np.NaN\n",
    "                frame_keypoints['j{}_y'.format(index)] = np.NaN\n",
    "                frame_keypoints['j{}_score'.format(index)] = np.NaN\n",
    "                frame_keypoints['j{}_l'.format(index)] = joint_order[index]\n",
    "            keypoints_array.append(frame_keypoints)\n",
    "            \n",
    "        else:\n",
    "            # If data for subject\n",
    "            frame_keypoints = {}\n",
    "            for index, keypoint in enumerate(frame['keypoints']):\n",
    "                frame_keypoints['j{}_x'.format(index)] = keypoint[0]\n",
    "                frame_keypoints['j{}_y'.format(index)] = keypoint[1]\n",
    "                frame_keypoints['j{}_score'.format(index)] = keypoint[2]\n",
    "                frame_keypoints['j{}_l'.format(index)] = joint_order[index]\n",
    "            keypoints_array.append(frame_keypoints)\n",
    "\n",
    "    # Create seperate dataframes (otherwise can't combine as >1-dimensional fields in pandas or numpy)\n",
    "    bbox_s = pd.DataFrame(bbox, columns=['bbox_left', 'bbox_top', 'bbox_right', 'bbox_bottom', 'bbox_score'])\n",
    "    area_s = pd.DataFrame(area, columns=['area'])\n",
    "    track_id_s = pd.DataFrame(track_id, columns=['track_id'])\n",
    "    keypoints_s = pd.DataFrame(keypoints_array)\n",
    "\n",
    "\n",
    "    # Create combined DataFrame\n",
    "    df = pd.concat([bbox_s,area_s,track_id_s,keypoints_s], axis=1)\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename(columns = {'index':'id'})\n",
    "    return df\n",
    "\n",
    "    #TODO(znoland): Set index as a frame number column (e.g. video1_frame_num)\n",
    "    #TODO(znoland): Add column with the name of the video?\n",
    "\n",
    "    \n",
    "df = raw_data_to_dataframe(raw_data)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# # Skip every other row\n",
    "# df = df.iloc[::2, :]\n",
    "# df = df.set_index('id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce4cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471001aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column names\n",
    "score_column_names = ['bbox_score']\n",
    "for i in range(17):\n",
    "    score_column_names.append('j{}_score'.format(i))\n",
    "\n",
    "pd.DataFrame(df[score_column_names].median()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3e6e8",
   "metadata": {},
   "source": [
    "### Visualize Scores - Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde137a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.show()\n",
    "sns.set(rc={'figure.figsize':(21,15)})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "n_rows=3\n",
    "n_cols=6\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols)\n",
    "\n",
    "# Set x axis limit (keep all charts on same axis)\n",
    "for row in axes:\n",
    "    for chart in row:\n",
    "        chart.set_xlim(0,1) \n",
    "\n",
    "for i, column in enumerate(df[score_column_names].columns):\n",
    "    ax = sns.histplot(df[column],ax=axes[i//n_cols,i%n_cols])\n",
    "    if column == 'bbox_score':\n",
    "        ax.set_title('bbox_score')\n",
    "    else: \n",
    "        ax.set_title(joint_order[i-1]) # Currently has bbox as well, so need to offset title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bc27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2d_skeleton_smoothness(df):\n",
    "    ''' Get Euclidean distance '''\n",
    "    \n",
    "    # Build dict to accumulate calcs\n",
    "    dict_2d_smth = {}\n",
    "    for j in range(17):\n",
    "            joint_field = 'j{}_euc_dist'.format(j)\n",
    "            dict_2d_smth[joint_field] = []\n",
    "\n",
    "    # Iterate through rows (Standard shift(-1) can't be used with this calc, so must iterate)\n",
    "    for i in range(len(df)):\n",
    "        for j in range(17):\n",
    "            joint_field_x = 'j{}_x'.format(j)\n",
    "            joint_field_y = 'j{}_y'.format(j)\n",
    "            joint_field_score = 'j{}_score'.format(j)\n",
    "            \n",
    "            #TODO(znoland): return NaN when score below certain amount?\n",
    "            \n",
    "            try:\n",
    "                dict_2d_smth['j{}_euc_dist'.format(j)].append(\n",
    "                    euclidean_dist(\n",
    "                        np.array([df.loc[i, joint_field_x], df.loc[i, joint_field_y]]), \n",
    "                        np.array([df.loc[i+1, joint_field_x], df.loc[i+1, joint_field_y]])\n",
    "                    )\n",
    "                )\n",
    "            except:\n",
    "                print('skiped row {}'.format(i))\n",
    "\n",
    "    return pd.DataFrame(dict_2d_smth)\n",
    "\n",
    "df_2d_smth = f2d_skeleton_smoothness(df)\n",
    "df_2d_smth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median distance between joints and previous frame by joint\n",
    "df_euc_by_joint = pd.DataFrame(df_2d_smth.median()).T\n",
    "df_euc_by_joint.columns = joint_order\n",
    "df_euc_by_joint.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd3bf2",
   "metadata": {},
   "source": [
    "### Visualize Sample Euclidean Distance - Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2645c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.show()\n",
    "sns.set(rc={'figure.figsize':(21,15)})\n",
    "\n",
    "# df_2d_smth.j0_euc_dist.hist()\n",
    "# sns.histplot(df_2d_smth).show()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "n_rows=3\n",
    "n_cols=6\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols)\n",
    "\n",
    "# Set x axis limit (keep all charts on same axis)\n",
    "for row in axes:\n",
    "    for chart in row:\n",
    "        chart.set_xlim(0,df_2d_smth.quantile(0.90).max()) # df_2d_smth.max().max()\n",
    "\n",
    "for i, column in enumerate(df_2d_smth.columns):\n",
    "    ax = sns.histplot(df_2d_smth[column],ax=axes[i//n_cols,i%n_cols])\n",
    "    ax.set_title(joint_order[i]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672c70",
   "metadata": {},
   "source": [
    "## Load example ground truth video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bd624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('work_dirs/tumeke_testing/ground_truth_labels/AFG_subject_switching_close_nurses_subjects1_partial.json') as f:\n",
    "  labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777faf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa422b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(labels[0]['pose-keypoints'])\n",
    "\n",
    "# test['x_px'] = (test['x']) / 100.0 * test['original_width']\n",
    "# test['y_px'] = (test['y']) / 100.0 * test['original_height']\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.pyplot import figure\n",
    "# import matplotlib.image as mpimg \n",
    "# from scipy import ndimage\n",
    "\n",
    "# img = mpimg.imread('work_dirs/tumeke_testing/ground_truth_images/BAR-S_water_ballon/00001274.jpg')\n",
    "# sns.scatterplot(data=test, x=\"x_px\", y=\"y_px\")\n",
    "# # ax.invert_yaxis()\n",
    "# # width_perc = 720 / 1280\n",
    "# # plt.rcParams[\"figure.figsize\"] = (10 * width_perc, 10)\n",
    "# # plt.xlim(0, 720)\n",
    "# # plt.ylim(0, 1280)\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9777cf6a",
   "metadata": {},
   "source": [
    "## Structure ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, id, keypoints (j0_x, j0_y)\n",
    "\n",
    "# 1) loop through each frame\n",
    "# 2) take the first person (wait till we have the relationships)\n",
    "# 3) pivot into dataframe like previous function for ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe632db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795dec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "joint_order = [\n",
    "    'Nose', \n",
    "    'L_Eye', \n",
    "    'R_Eye', \n",
    "    'L_Ear', \n",
    "    'R_Ear', \n",
    "    'L_Shoulder', \n",
    "    'R_Shoulder', \n",
    "    'L_Elbow', \n",
    "    'R_Elbow', \n",
    "    'L_Wrist', \n",
    "    'R_Wrist', \n",
    "    'L_Hip', \n",
    "    'R_Hip', \n",
    "    'L_Knee', \n",
    "    'R_Knee', \n",
    "    'L_Ankle', \n",
    "    'R_Ankle' \n",
    "]\n",
    "\n",
    "def extract_x_and_y(joint):\n",
    "    return np.array([joint['x'], joint['y']])\n",
    "\n",
    "\n",
    "def closest_subject_heuristic_raw(keypoint_obj):\n",
    "    '''Get avg euclidean distance between right shoulder/elbow, left shoulder/elbow, right shoulder/hip and left shoulder/hip''' \n",
    "    r_shoulder_i = joint_order.index('R_Shoulder')\n",
    "    r_elbow_i = joint_order.index('R_Elbow')\n",
    "    r_hip_i= joint_order.index('R_Hip')\n",
    "    l_shoulder_i = joint_order.index('L_Shoulder')\n",
    "    l_elbow_i = joint_order.index('L_Elbow')\n",
    "    l_hip_i = joint_order.index('L_Hip')\n",
    "    \n",
    "    r_se_ed = euclidean_dist(extract_x_and_y(keypoint_obj[r_shoulder_i]), extract_x_and_y(keypoint_obj[r_elbow_i]))\n",
    "    r_sh_ed = euclidean_dist(extract_x_and_y(keypoint_obj[r_shoulder_i]), extract_x_and_y(keypoint_obj[r_hip_i]))\n",
    "    l_se_ed = euclidean_dist(extract_x_and_y(keypoint_obj[l_shoulder_i]), extract_x_and_y(keypoint_obj[l_elbow_i]))\n",
    "    l_sh_ed = euclidean_dist(extract_x_and_y(keypoint_obj[l_shoulder_i]), extract_x_and_y(keypoint_obj[l_hip_i]))\n",
    "    return np.array([r_se_ed, r_sh_ed, l_se_ed, l_sh_ed]).mean()\n",
    "\n",
    "\n",
    "def ground_truth_processing(labels):\n",
    "    '''Tranform ground truth data into data frame\n",
    "\n",
    "        1) Get Subjects\n",
    "\n",
    "        2) Get Keypoints for each subject\n",
    "\n",
    "        3) Order subjects by heuristic\n",
    "\n",
    "    '''\n",
    "\n",
    "    frame_array = []\n",
    "\n",
    "    for label in labels:\n",
    "    #     label = label_r[0]\n",
    "        # label = labels[0:1][0]\n",
    "\n",
    "        row = {}\n",
    "\n",
    "        # Metadata\n",
    "        img_name = re.search(r'(\\d\\d+)', label['data']['img']).group(0)\n",
    "        row['id'] = int(img_name)\n",
    "        row['ls_id'] = label['id']\n",
    "        row['img'] = label['data']['img']\n",
    "        row['subjects'] = []\n",
    "\n",
    "        #Subjects\n",
    "        persons_t = [p for p in label['annotations'][0]['result'] if p['type'] == 'rectanglelabels']\n",
    "\n",
    "        # Keypoints\n",
    "        keypoints_t = [k for k in label['annotations'][0]['result'] if k['type'] == 'keypointlabels']\n",
    "\n",
    "        for i, person in enumerate(persons_t):\n",
    "\n",
    "            # Filter on subject's keypoints\n",
    "            person_keypoints_t = [k for k in keypoints_t if k['parentID'] == person['id']]\n",
    "            # Filter out unused keypoints\n",
    "            person_keypoints_t = [k for k in person_keypoints_t if k['value']['keypointlabels'][0] in joint_order]\n",
    "\n",
    "             # Set order of keypoints + set placeholders when null\n",
    "            person_keypoints_sorted = []\n",
    "            for i, joint_name in enumerate(joint_order):\n",
    "                target_keypoint = [k for k in person_keypoints_t if k['value']['keypointlabels'][0] == joint_name]\n",
    "\n",
    "                if target_keypoint:\n",
    "                    original_width = target_keypoint[0]['original_width']\n",
    "                    original_height = target_keypoint[0]['original_height']\n",
    "                    target_keypoint = target_keypoint[0]['value']\n",
    "                    target_keypoint['original_width'] = original_width\n",
    "                    target_keypoint['original_height'] = original_height\n",
    "                else:\n",
    "                    target_keypoint = {'x': np.nan, 'y': np.nan, 'width': np.nan, 'keypointlabels': [joint_name], 'original_width': np.nan, 'original_height': np.nan, }\n",
    "\n",
    "                person_keypoints_sorted.append(target_keypoint)\n",
    "\n",
    "            subject_t = {\n",
    "                'name': person['value']['rectanglelabels'][0],\n",
    "                'id': person['id'],\n",
    "                'pose-keypoints': person_keypoints_sorted,\n",
    "                'closest-subject-heuristic': closest_subject_heuristic_raw(person_keypoints_sorted)\n",
    "            }\n",
    "            row['subjects'].append(subject_t)\n",
    "\n",
    "\n",
    "        # Sort subjects by heuristic\n",
    "        row['subjects'] = sorted(row['subjects'], key=lambda x: x['closest-subject-heuristic'], reverse=True)\n",
    "\n",
    "        # Format x & y coordinates (for 1st subject only)\n",
    "        for index, keypoint in enumerate(row['subjects'][0]['pose-keypoints']):\n",
    "            if len(keypoint['keypointlabels']) > 1:\n",
    "                raise ValueError('There are multiple labels for one keypoint!') \n",
    "            row['j{}_x'.format(index)] = keypoint['x'] / 100.0 * keypoint['original_width']\n",
    "            row['j{}_y'.format(index)] = keypoint['y'] / 100.0 * keypoint['original_height']\n",
    "            row['j{}_l'.format(index)] = keypoint['keypointlabels'][0]\n",
    "\n",
    "        frame_array.append(row)\n",
    "        \n",
    "    return frame_array\n",
    "\n",
    "# raw array is \"frame_array\" !\n",
    "gt_frame_array = ground_truth_processing(labels)\n",
    "gt_df = pd.DataFrame(gt_frame_array)\n",
    "# Order by ID\n",
    "gt_df = gt_df.sort_values(by='id')\n",
    "gt_df = gt_df.reset_index(drop=True)\n",
    "gt_df = gt_df.set_index('id')\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df['subjects'].loc[[2]].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd03b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf23b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLDER METHOD FOR SIGNLE SUBJECT VIDEOS\n",
    "\n",
    "# import re\n",
    "\n",
    "# joint_order = [\n",
    "#     'Nose', \n",
    "#     'L_Eye', \n",
    "#     'R_Eye', \n",
    "#     'L_Ear', \n",
    "#     'R_Ear', \n",
    "#     'L_Shoulder', \n",
    "#     'R_Shoulder', \n",
    "#     'L_Elbow', \n",
    "#     'R_Elbow', \n",
    "#     'L_Wrist', \n",
    "#     'R_Wrist', \n",
    "#     'L_Hip', \n",
    "#     'R_Hip', \n",
    "#     'L_Knee', \n",
    "#     'R_Knee', \n",
    "#     'L_Ankle', \n",
    "#     'R_Ankle' \n",
    "# ]\n",
    "\n",
    "# def ground_truth_etl(labels):\n",
    "#     '''Tranform ground truth data into data frame'''\n",
    "#     frame_array = []\n",
    "#     for label in labels:\n",
    "#         row = {}\n",
    "#         img_name = re.search(r'(\\d\\d+)', label['img']).group(0)\n",
    "#         row['id'] = int(img_name)\n",
    "#         row['ls_id'] = label['id']\n",
    "#         row['img'] = label['img']\n",
    "        \n",
    "#         # Filter out unused keypoints\n",
    "#         label['pose-keypoints'] = [keypoint for keypoint in label['pose-keypoints'] if keypoint['keypointlabels'][0] in joint_order]\n",
    "#         # Set order of keypoints\n",
    "#         label['pose-keypoints'].sort(key=lambda x: joint_order.index(x['keypointlabels'][0]))\n",
    "\n",
    "#         for index, keypoint in enumerate(label['pose-keypoints']):\n",
    "#             if len(keypoint['keypointlabels']) > 1:\n",
    "#                 raise ValueError('There are multiple labels for one keypoint!') \n",
    "#             row['j{}_x'.format(index)] = keypoint['x'] / 100.0 * keypoint['original_width']\n",
    "#             row['j{}_y'.format(index)] = keypoint['y'] / 100.0 * keypoint['original_height']\n",
    "#             row['j{}_l'.format(index)] = keypoint['keypointlabels'][0]\n",
    "\n",
    "#         frame_array.append(row)\n",
    "        \n",
    "#     return pd.DataFrame(frame_array)\n",
    "        \n",
    "# gt_df = ground_truth_etl(labels)\n",
    "# # Order by ID\n",
    "# gt_df = gt_df.sort_values(by='id')\n",
    "# gt_df = gt_df.reset_index(drop=True)\n",
    "# gt_df = gt_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: IT APPEARS AS IF A ROW IS NOT RETURNED WHEN a frame is not labeled!!!\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.image as mpimg \n",
    "from scipy import ndimage\n",
    "import re\n",
    "\n",
    "def visualize_gt_frame(frame_row):\n",
    "    img_name = re.search(r'(\\d+[.][jpg]+)', frame_row['img'].values[0]).group(0)\n",
    "    img = mpimg.imread('work_dirs/tumeke_testing/ground_truth_images/BAR-S_water_ballon/{}'.format(img_name))\n",
    "    for j in range(17): # 19 originally\n",
    "        x = \"j{}_x\".format(j)\n",
    "        y = \"j{}_y\".format(j)\n",
    "        l = \"j{}_l\".format(j)\n",
    "        p1 = sns.scatterplot(data=frame_row, x=x, y=y)\n",
    "        # Add text besides each point\n",
    "        p1.text(frame_row[x]+10, frame_row[y], \n",
    "             frame_row[l].values[0], horizontalalignment='left', \n",
    "             size=7, color='white', weight='regular')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177eecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_gt_frame(gt_df[0:1])\n",
    "# visualize_gt_frame(gt_df[20:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532491d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_df[0:1].img.values[0] # 1 indexed - The frame number is the image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ff8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_overlap(frame_number):\n",
    "    gt_f = gt_df.loc[[frame_number]]\n",
    "    f = df.loc[[frame_number]]\n",
    "    w_f = wrnch_df.loc[[frame_number]]\n",
    "    \n",
    "    frame_img_name = re.search(r'(\\d+[.][jpg]+)', gt_f['img'].values[0]).group(0)\n",
    "    file_img_name = re.findall(r'/([0-9a-zA-Z-_]+)', gt_df[0:1].img.values[0])[1]\n",
    "    img = mpimg.imread('work_dirs/tumeke_testing/ground_truth_images/{}/{}'.format(file_img_name, frame_img_name))\n",
    "    \n",
    "    for j in range(17):\n",
    "        x = \"j{}_x\".format(j)\n",
    "        y = \"j{}_y\".format(j)\n",
    "        l = \"j{}_l\".format(j)\n",
    "        # Ground Truth - BLUE\n",
    "        p1 = sns.scatterplot(data=gt_f, x=x, y=y, color='blue')\n",
    "        p1.text(gt_f[x]-70, gt_f[y], \n",
    "             gt_f[l].values[0], horizontalalignment='left', \n",
    "             size=7, color='blue', weight='regular')\n",
    "        # Hrnet Model - RED\n",
    "        p2 = sns.scatterplot(data=f, x=x, y=y, color='red')\n",
    "        p2.text(f[x]+20, f[y]-1, \n",
    "             f[l].values[0], horizontalalignment='left', \n",
    "             size=7, color='red', weight='regular')\n",
    "        \n",
    "        # Wrnch - GREEN\n",
    "        p3 = sns.scatterplot(data=w_f, x=x, y=y, color='green')\n",
    "        p3.text(w_f[x]+20, w_f[y]+1, \n",
    "             w_f[l].values[0], horizontalalignment='left', \n",
    "             size=7, color='green', weight='regular')\n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "visualize_overlap(1000) # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e63596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = df['j0_x'] / gt_df['j0_x']\n",
    "# test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4561bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[[600]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0dae2",
   "metadata": {},
   "source": [
    "## PCK - Percentage of Correct Key-points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a5f96",
   "metadata": {},
   "source": [
    "Description: https://github.com/cbsudux/Human-Pose-Estimation-101#percentage-of-correct-parts---pcp\n",
    "\n",
    "\n",
    "Percentage of Correct Key-points - PCK:\n",
    "* Detected joint is considered correct if the distance between the predicted and the true joint is within a certain threshold (threshold varies)\n",
    "* PCKh@0.5 is when the threshold = 50% of the head bone link\n",
    "* PCK@0.2 == Distance between predicted and true joint < 0.2 * torso diameter\n",
    "* Sometimes 150 mm is taken as the threshold\n",
    "* Head, shoulder, Elbow, Wrist, Hip, Knee, Ankle → Keypoints\n",
    "* PCK is used for 2D and 3D (PCK3D)\n",
    "* Higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pelvis is in the middle of l_hip and r_hip\n",
    "# keypoints_new[0] = (keypoints[11] + keypoints[12]) / 2\n",
    "# thorax is in the middle of l_shoulder and r_shoulder\n",
    "# keypoints_new[8] = (keypoints[5] + keypoints[6]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae130487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT !!!!!!!!!!! - THIS IS A TEST - CHANGE BACK!\n",
    "# df = wrnch_df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae80134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_j_pos(f, v, joint_name):\n",
    "    return f['j{}_{}'.format(joint_order.index(joint_name), v)]\n",
    "\n",
    "def get_torso_diameter(x):\n",
    "    return euclidean_dist(np.array([x['pelvis_x'], x['pelvis_y']]), np.array([x['thorax_x'], x['thorax_y']]))\n",
    "\n",
    "for df_i in [df, gt_df]:\n",
    "    \n",
    "    df_i['pelvis_x'] = (extract_j_pos(df_i, 'x', 'L_Hip') + extract_j_pos(df_i, 'x', 'R_Hip')) / 2\n",
    "    df_i['pelvis_y'] = (extract_j_pos(df_i, 'y', 'L_Hip') + extract_j_pos(df_i, 'y', 'R_Hip')) / 2\n",
    "    df_i['thorax_x'] = (extract_j_pos(df_i, 'x', 'L_Shoulder') + extract_j_pos(df_i, 'x', 'R_Shoulder')) / 2\n",
    "    df_i['thorax_y'] = (extract_j_pos(df_i, 'y', 'L_Shoulder') + extract_j_pos(df_i, 'y', 'R_Shoulder')) / 2\n",
    "    \n",
    "    df_i['torso_diameter'] = df_i.apply(lambda x: get_torso_diameter(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Iterate through keypoints and check \n",
    "#    - distance between predicted and true joint < 0.2 * torso diameter\n",
    "\n",
    "# 2) for row, get jX_d (joint detected)\n",
    "\n",
    "# 3) Get percent of all values detected (across all keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "pck_threshold_s = .20 * gt_df['torso_diameter']\n",
    "pck_threshold_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_duclidean_dist(df1, df2, cols=['x_coord','y_coord']):\n",
    "    return np.linalg.norm(df1[cols].values - df2[cols].values, axis=1)\n",
    "\n",
    "pck_df_raw = gt_df[[]] # Return just index\n",
    "for j in range(17):\n",
    "    x = \"j{}_x\".format(j)\n",
    "    y = \"j{}_y\".format(j)\n",
    "    pck_df_raw['{}_ed'.format(joint_order[j])] = vect_duclidean_dist(gt_df, df.iloc[gt_df.index], cols=[x,y])\n",
    "    # pck_df['{}'.format(joint_order[j])] = vec_euclidean_dist(gt_df[[x,y]], df.iloc[gt_df.index][[x,y]])\n",
    "\n",
    "pck_df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pck_df_scores = pck_df_raw.lt(pck_threshold_s, axis='index') # True if distance less than PCK threshold\n",
    "pck_df_scores = pck_df_scores.applymap(lambda x: 1 if x == True else 0)\n",
    "pck_df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Detected frames\n",
    "pck_df_scores.sum(axis=1).apply(lambda x: 1 if x > 0 else 0).sum() / pck_df_scores.sum(axis=1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total (all frames)\n",
    "pck_df_scores.sum(axis=1).sum() / pck_df_scores.count(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total (detected frames)\n",
    "pck_detected_df = pck_df_scores.sum(axis=1).apply(lambda x: True if x > 0 else False)\n",
    "pck_df_scores[pck_detected_df].sum(axis=1).sum() / pck_df_scores[pck_detected_df].count(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96367f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Body part\n",
    "pck_df_scores.sum() / pck_df_scores.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by frame\n",
    "# pd.DataFrame(pck_df_scores.sum(axis=1) / pck_df_scores.count(axis=1), columns=['PCK']).plot.area()\n",
    "pd.DataFrame(pck_df_scores).plot.area(title='PCK over time by joint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10801765",
   "metadata": {},
   "source": [
    "## PCP - Percentage of Correct Parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4502aef",
   "metadata": {},
   "source": [
    "https://github.com/cbsudux/Human-Pose-Estimation-101#percentage-of-correct-parts---pcp\n",
    "\n",
    "### Percentage of Correct Parts - PCP\n",
    "* A limb is considered detected and a correct part if the distance between the two predicted joint locations and the true limb joint locations is at most half of the limb length (PCP at 0.5 )\n",
    "* Measures detection rate of limbs\n",
    "* Cons - penalizes shorter limbs\n",
    "\n",
    "Calculation:\n",
    "* For a specific part, PCP = (No. of correct parts for entire dataset) / (No. of total parts for entire dataset)\n",
    "* Take a dataset with 10 images and 1 pose per image. Each pose has 8 parts - ( upper arm, lower arm, upper leg, lower leg ) x2\n",
    "* No of upper arms = 10 * 2 = 20\n",
    "* No of lower arms = 20\n",
    "* No of lower legs = No of upper legs = 20\n",
    "* If upper arm is detected correct for 17 out of the 20 upper arms i.e 17 ( 10 right arms and 7 left) → PCP = 17/20 = 85%\n",
    "\n",
    "Higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) ground truth limb length\n",
    "\n",
    "# 2) Euclidean distance between joints (already done) + avg between start joint and end joint euclidean distances\n",
    "\n",
    "# 3) Check if limb ed is less than threshold (ground truth limb length * .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b89238",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ground Truth Limb Length'''\n",
    "limbs = [\n",
    "    {'name':'L_upper_arm', 'joints': [joint_order.index('L_Shoulder'), joint_order.index('L_Elbow')]},\n",
    "    {'name':'R_upper_arm', 'joints': [joint_order.index('R_Shoulder'), joint_order.index('R_Elbow')]},\n",
    "    {'name':'L_lower_arm', 'joints': [joint_order.index('L_Elbow'), joint_order.index('L_Wrist')]},\n",
    "    {'name':'R_lower_arm', 'joints': [joint_order.index('R_Elbow'), joint_order.index('R_Wrist')]},\n",
    "    {'name':'L_upper_leg', 'joints': [joint_order.index('L_Hip'), joint_order.index('L_Knee')]},\n",
    "    {'name':'R_upper_leg', 'joints': [joint_order.index('R_Hip'), joint_order.index('R_Knee')]},\n",
    "    {'name':'L_lower_leg', 'joints': [joint_order.index('L_Knee'), joint_order.index('L_Ankle')]},\n",
    "    {'name':'R_lower_leg', 'joints': [joint_order.index('R_Knee'), joint_order.index('R_Ankle')]}\n",
    "]\n",
    "\n",
    "# def get_limb_diameter(r):\n",
    "#     return euclidean_dist(np.array([r[x1], r[y1]]), np.array([r[x2], r[y2]]))\n",
    "\n",
    "pcp_gt_limb_length_df = gt_df[[]] # Return just index\n",
    "for limb in limbs:\n",
    "    # Get ground truth limb length\n",
    "    j1 = limb['joints'][0] # joint 1 index\n",
    "    j2 = limb['joints'][1] # joint 2 index\n",
    "    x1 = \"j{}_x\".format(j1)\n",
    "    y1 = \"j{}_y\".format(j1)\n",
    "    x2 = \"j{}_x\".format(j2)\n",
    "    y2 = \"j{}_y\".format(j2)\n",
    "    pcp_gt_limb_length_df[limb['name']] = gt_df.apply(lambda r: euclidean_dist(np.array([r[x1], r[y1]]), np.array([r[x2], r[y2]])), axis=1)\n",
    "\n",
    "pcp_gt_limb_length_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad552c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PCP Theshold'''\n",
    "pcp_threshold_df = pcp_gt_limb_length_df * 0.50\n",
    "pcp_threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00693586",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Limb Euclidean Dist'''\n",
    "limbs = [\n",
    "    {'name':'L_upper_arm', 'joints': ['L_Shoulder', 'L_Elbow']},\n",
    "    {'name':'R_upper_arm', 'joints': ['R_Shoulder', 'R_Elbow']},\n",
    "    {'name':'L_lower_arm', 'joints': ['L_Elbow', 'L_Wrist']},\n",
    "    {'name':'R_lower_arm', 'joints': ['R_Elbow', 'R_Wrist']},\n",
    "    {'name':'L_upper_leg', 'joints': ['L_Hip', 'L_Knee']},\n",
    "    {'name':'R_upper_leg', 'joints': ['R_Hip', 'R_Knee']},\n",
    "    {'name':'L_lower_leg', 'joints': ['L_Knee', 'L_Ankle']},\n",
    "    {'name':'R_lower_leg', 'joints': ['R_Knee', 'R_Ankle']}\n",
    "]\n",
    "\n",
    "pcp_limb_ed_df = gt_df[[]] # Return just index\n",
    "for limb in limbs:\n",
    "    j1 = limb['joints'][0] # joint 1 name\n",
    "    j2 = limb['joints'][1] # joint 2 name\n",
    "    \n",
    "    pcp_limb_ed_df[limb['name']] = pck_df_raw['{}_ed'.format(j1)] + pck_df_raw['{}_ed'.format(j2)] / 2\n",
    "    \n",
    "pcp_limb_ed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcp_df_scores = pck_df_raw.lt(pck_threshold_s, axis='index') # True if distance less than PCP threshold\n",
    "# pcp_df_scores = pck_df_scores.applymap(lambda x: 1 if x == True else 0)\n",
    "# pcp_df_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_df_scores = pcp_limb_ed_df.lt(pcp_threshold_df)\n",
    "pcp_df_scores = pcp_df_scores.applymap(lambda x: 1 if x == True else 0)\n",
    "pcp_df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Detected frames\n",
    "pcp_df_scores.sum(axis=1).apply(lambda x: 1 if x > 0 else 0).sum() / pcp_df_scores.sum(axis=1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04947419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total (all frames)\n",
    "pcp_df_scores.sum(axis=1).sum() / pcp_df_scores.count(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4befd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total (detected frames)\n",
    "pcp_detected_df = pcp_df_scores.sum(axis=1).apply(lambda x: True if x > 0 else False)\n",
    "pcp_df_scores[pcp_detected_df].sum(axis=1).sum() / pcp_df_scores[pcp_detected_df].count(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d056a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Limb\n",
    "pcp_df_scores.sum() / pcp_df_scores.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ef3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by Frame\n",
    "pd.DataFrame(pcp_df_scores).plot.area(title='PCP over time by limb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb217a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update summary calcs!:\n",
    "# 1) For frames where there is an output, how accurate is that output? (if entire row = 0, then exclude row in calculation)\n",
    "# 2) Calculate number of detected frames (rows that have at least 1 value in threshold (row > 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ef9df",
   "metadata": {},
   "source": [
    "# Tests with Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fe1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tumeke_testing_modules import load_model_data, load_gt_data\n",
    "# from tumeke_testing_modules.visualize_frame import visualize_overlap\n",
    "# from tumeke_testing_modules.pck_calc import pck_calc\n",
    "# from tumeke_testing_modules.pcp_calc import pcp_calc\n",
    "# from tumeke_testing_modules.visualize_df_scores import visualize_df_scores\n",
    "# from tumeke_testing_modules.smoothness_calc import smoothness_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2364f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # file = 'AFG_subject_switching_close_nurses_subjects1_partial'\n",
    "# file = 'BAR-S_water_ballon_trimmed' # Need to export full annotation file, not partial\n",
    "\n",
    "# hrnet_df, wrnch_df = load_model_data.get_hrnet_wrnch_dfs(file)\n",
    "# gt_df = load_gt_data.get_gt_df(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_df_scores(hrnet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25246e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pck_calc(gt_df, hrnet_df, wrnch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_overlap(gt_df, hrnet_df, wrnch_df, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d26135",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pcp_calc(gt_df, hrnet_df, wrnch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52508f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# smoothness_calc(gt_df, hrnet_df, wrnch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b976c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29107f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2305c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_cuda10)",
   "language": "python",
   "name": "conda_pytorch_cuda10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
