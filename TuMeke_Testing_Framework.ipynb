{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ancient-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "args_pre = {\n",
    "    'det_config': 'demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py',\n",
    "    'det_checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth',\n",
    "    'pose_detector_config': 'configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py',\n",
    "    'pose_detector_checkpoint': 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth',\n",
    "    'pose_lifter_config': 'configs/body/3d_kpt_sview_rgb_vid/video_pose_lift/h36m/videopose3d_h36m_243frames_fullconv_supervised.py',\n",
    "    'pose_lifter_checkpoint': '/home/ubuntu/epoch_80.pth',\n",
    "    # Flags/Optional\n",
    "#     'video_path': 'demo/resources/jeldwen-1.mp4',\n",
    "    'rebase_keypoint_height': True,\n",
    "    'norm_pose_2d': None,\n",
    "    'num_instances': -1,\n",
    "    'show': False,\n",
    "    'out_video_root': 'vis_results',\n",
    "    'device': 'cuda:0',\n",
    "    'det_cat_id': 1,\n",
    "    'bbox_thr': 0.9,\n",
    "    'kpt_thr': 0.3,\n",
    "    'use_oks_tracking': None,\n",
    "    'tracking_thr': 0.3,\n",
    "    'euro': None,\n",
    "    'radius': 8,\n",
    "    'thickness': 2,\n",
    "    'detections_2d': ''\n",
    "}\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(**args_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mobile-rochester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "from demo import zach_v_body3d_two_stage_video as m_2d_3d_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "photographic-patch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "Stage #1: 2D pose detection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Can not load dataset from config. Use default CLASSES instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Model\n",
      "Video len: 449\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.37624287605285645\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0706181526184082\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0710151195526123\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.06760764122009277\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08623981475830078\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08818316459655762\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08850550651550293\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09654068946838379\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1160736083984375\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1355273723602295\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12172675132751465\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11413097381591797\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.15172958374023438\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09258270263671875\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09333491325378418\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09406876564025879\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09136652946472168\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07991385459899902\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08750510215759277\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09078073501586914\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08776593208312988\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12053155899047852\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12169432640075684\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11499404907226562\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11132264137268066\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12357211112976074\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.14845848083496094\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10566353797912598\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11592769622802734\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11511445045471191\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10047078132629395\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1239478588104248\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1060333251953125\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1081697940826416\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12125086784362793\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.13454794883728027\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1737070083618164\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.2338695526123047\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1261003017425537\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.15643596649169922\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.25756096839904785\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11315679550170898\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10671830177307129\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1620192527770996\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1604013442993164\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11144876480102539\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11181044578552246\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11746954917907715\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11158561706542969\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12354373931884766\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08982419967651367\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11844658851623535\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1264512538909912\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12854671478271484\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.29123997688293457\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.2476346492767334\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08422183990478516\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08416438102722168\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.19745612144470215\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.083740234375\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09357070922851562\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.17834806442260742\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09960484504699707\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08657050132751465\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09405207633972168\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08673381805419922\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.06711792945861816\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08686232566833496\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08742904663085938\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11539077758789062\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10921287536621094\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08720993995666504\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09340381622314453\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.17711210250854492\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11367225646972656\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10997629165649414\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11493039131164551\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11907410621643066\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10617327690124512\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09653615951538086\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0986032485961914\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09507346153259277\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1123361587524414\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09055948257446289\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.14530634880065918\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07575702667236328\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07592058181762695\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07585883140563965\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07564496994018555\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0844874382019043\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07541012763977051\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08426380157470703\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07573533058166504\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0771629810333252\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07548713684082031\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07826972007751465\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07553315162658691\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0815122127532959\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07553648948669434\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07894182205200195\n",
      "Idx: 100\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07655787467956543\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08147549629211426\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07674694061279297\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08095383644104004\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0771329402923584\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07688450813293457\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08365488052368164\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07525134086608887\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07768535614013672\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0763087272644043\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.21202540397644043\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07629942893981934\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08492016792297363\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0775754451751709\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07988166809082031\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0892641544342041\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07973456382751465\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07925939559936523\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08962130546569824\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07864022254943848\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.07967090606689453\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08830690383911133\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08104372024536133\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08141040802001953\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08958029747009277\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09051346778869629\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1644725799560547\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09066462516784668\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08983230590820312\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09590911865234375\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09419131278991699\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10059666633605957\n",
      "Shape torch.Size([1, 3, 768, 1344])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.171433687210083\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09967947006225586\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08575940132141113\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10270166397094727\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08600091934204102\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09352254867553711\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08805584907531738\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09211874008178711\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09403061866760254\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.093719482421875\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09387993812561035\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0904083251953125\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08834123611450195\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08794403076171875\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08803987503051758\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08795928955078125\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11007094383239746\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09348487854003906\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08800387382507324\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08811616897583008\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09394145011901855\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08969354629516602\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09457755088806152\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09203457832336426\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08827090263366699\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08832836151123047\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09006905555725098\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08986639976501465\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0904996395111084\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09071040153503418\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08820652961730957\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09210824966430664\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0944368839263916\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09423947334289551\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09001612663269043\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.17073321342468262\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09549474716186523\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08867645263671875\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08844351768493652\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11637115478515625\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08922433853149414\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08849453926086426\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08824491500854492\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12043046951293945\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0938863754272461\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08846664428710938\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.17934584617614746\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11208629608154297\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09667515754699707\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0898582935333252\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11665749549865723\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09617304801940918\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09431052207946777\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10822868347167969\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0929117202758789\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0903768539428711\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09035730361938477\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.2664070129394531\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09120631217956543\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1006629467010498\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.19219446182250977\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0928499698638916\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0899052619934082\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09310269355773926\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09155559539794922\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09080648422241211\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.18498468399047852\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08960604667663574\n",
      "Idx: 200\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08989119529724121\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09240150451660156\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1372208595275879\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0955350399017334\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09417366981506348\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.08999180793762207\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09100055694580078\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0934751033782959\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0901336669921875\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09044170379638672\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09390139579772949\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09171438217163086\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09147953987121582\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09178590774536133\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09287428855895996\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09177684783935547\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0918123722076416\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.22601914405822754\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09178042411804199\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09200787544250488\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09229826927185059\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11465096473693848\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12961268424987793\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0981898307800293\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09446382522583008\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09202885627746582\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10489535331726074\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09415817260742188\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09408879280090332\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09373879432678223\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09207725524902344\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09226870536804199\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09190583229064941\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11136627197265625\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0942697525024414\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09138774871826172\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09242081642150879\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09153366088867188\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09171509742736816\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09949874877929688\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09911513328552246\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0913095474243164\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09163689613342285\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09268665313720703\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1014699935913086\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09250807762145996\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0916132926940918\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09282827377319336\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.14575552940368652\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09470796585083008\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09659814834594727\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09262657165527344\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09598088264465332\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09243631362915039\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09221458435058594\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09260821342468262\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09650778770446777\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09876036643981934\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0936284065246582\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09168267250061035\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09273982048034668\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09153938293457031\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09202957153320312\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09171628952026367\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09951925277709961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0952463150024414\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09434938430786133\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09177732467651367\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09315729141235352\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09363675117492676\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10365629196166992\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09917330741882324\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09439706802368164\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09400081634521484\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10064482688903809\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09452128410339355\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09436535835266113\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09380245208740234\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09369397163391113\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12441325187683105\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09358787536621094\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09452056884765625\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09348011016845703\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09368515014648438\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09447836875915527\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09393882751464844\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09388256072998047\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09349751472473145\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10883045196533203\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1226816177368164\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09661507606506348\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0959324836730957\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10114789009094238\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09989047050476074\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0963127613067627\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09594368934631348\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1054997444152832\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09620785713195801\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09580850601196289\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09602069854736328\n",
      "Idx: 300\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10469245910644531\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09614872932434082\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0969688892364502\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09589004516601562\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09616422653198242\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10345172882080078\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09582209587097168\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09584808349609375\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10539937019348145\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1000361442565918\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09621262550354004\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09642577171325684\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1024630069732666\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09680485725402832\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09590888023376465\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1050255298614502\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10098671913146973\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09654378890991211\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1039896011352539\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09683823585510254\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09697747230529785\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10684728622436523\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09617352485656738\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09595251083374023\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10510849952697754\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.16875553131103516\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10732674598693848\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09772992134094238\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09682941436767578\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09695744514465332\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10577821731567383\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09915971755981445\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1000833511352539\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10703372955322266\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0998082160949707\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09797430038452148\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09606194496154785\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1799936294555664\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09728503227233887\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0973348617553711\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1073446273803711\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.20144867897033691\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10410618782043457\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1162717342376709\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09715867042541504\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10961103439331055\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09706997871398926\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10407519340515137\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10695075988769531\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0975344181060791\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09712791442871094\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10138440132141113\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12717747688293457\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.14075136184692383\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1302814483642578\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11156797409057617\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11785030364990234\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1120138168334961\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.13188385963439941\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.13518047332763672\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12729191780090332\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.13714051246643066\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12477803230285645\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.13309288024902344\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.2374129295349121\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09712386131286621\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10712337493896484\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09720754623413086\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09789848327636719\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10787057876586914\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10186767578125\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09942150115966797\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09699153900146484\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.19511961936950684\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09728074073791504\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10381674766540527\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.24136805534362793\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09652304649353027\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10568666458129883\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09742927551269531\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09727025032043457\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09806513786315918\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10089111328125\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10567545890808105\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09745383262634277\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10083961486816406\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09740948677062988\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10669493675231934\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09696316719055176\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09833765029907227\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09692215919494629\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10628509521484375\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09749078750610352\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09693598747253418\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1061410903930664\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09705138206481934\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10546159744262695\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09914946556091309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09734725952148438\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10433745384216309\n",
      "Idx: 400\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.14401936531066895\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1064143180847168\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10529398918151855\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.16577768325805664\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09705328941345215\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09725618362426758\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.17645859718322754\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09824728965759277\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09690332412719727\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09753179550170898\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10859251022338867\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0972895622253418\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10326313972473145\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09716153144836426\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.12126684188842773\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0955510139465332\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10381031036376953\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11400866508483887\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1007390022277832\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09726071357727051\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.11132669448852539\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09767389297485352\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10218095779418945\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10172009468078613\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.1123661994934082\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09716081619262695\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10631847381591797\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09708261489868164\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.0968024730682373\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09792065620422363\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09723782539367676\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10660886764526367\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10041952133178711\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09851765632629395\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09797906875610352\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10764479637145996\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10046887397766113\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09967541694641113\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10487842559814453\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09669852256774902\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09695959091186523\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09880805015563965\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09723329544067383\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09669113159179688\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10793519020080566\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10529351234436035\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10497498512268066\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.10066437721252441\n",
      "Shape torch.Size([1, 3, 768, 1344])\n",
      "Time: 0.09693121910095215\n",
      "Stage 2: 2D-to-3D pose lifting.\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 449/449, 8.9 task/s, elapsed: 50s, ETA:     0s\n",
      "Video \"vid1\" processed.\n",
      "Total time: 105.79774498939514\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "# Test one video\n",
    "import time\n",
    "args.video_name = 'vid1'\n",
    "args.file_path = 'demo/resources/test_vids/vid1.mp4'\n",
    "args.detections_2d = \"\"\n",
    "# args.file_path = 'demo/resources/test_vids/gHO_sBM_c08_d20_mHO0_ch10.mp4'\n",
    "t1 = time.time()\n",
    "m_2d_3d_model.process_video(args)\n",
    "print(f\"Total time: {time.time() - t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "video_directory = 'evaluation_vids'\n",
    "\n",
    "def get_video_list():\n",
    "    '''Get list of videos to process'''\n",
    "    file_paths = glob.glob(\"demo/resources/{}/*\".format(video_directory))\n",
    "    video_names = []\n",
    "    \n",
    "    for path in file_paths:\n",
    "        video_names.append(\n",
    "            SimpleNamespace(\n",
    "                **{\n",
    "                    'video_name': re.search('/.*/.*/(.*)(?:[.])', path).group(1),\n",
    "                    'file_path': 'demo/resources/{}/'.format(video_directory) + re.search('/.*/.*/(.*)', path).group(1)\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return video_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos():\n",
    "    '''Iterate through videos and process'''\n",
    "    video_list = get_video_list()\n",
    "    print(video_list)\n",
    "    for video in video_list:\n",
    "        args.video_name = video.video_name\n",
    "        args.file_path = video.file_path\n",
    "        m_2d_3d_model.process_video(args)\n",
    "        \n",
    "process_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c1077",
   "metadata": {},
   "source": [
    "# Loading wrnch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478cb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "filename = 'work_dirs/tumeke_testing/wrnch_jsons/AFG_subject_switching_close_nurses_subjects1_partial.json'\n",
    "f = open(filename, \"r\")\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b075103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrnch_raw_data():\n",
    "    standard_format_data = []\n",
    "    wrnch_to_hrnet = [16, 19, 17, 20, 18, 13, 12, 14, 11, 15, 10, 3, 2, 4, 1, 5, 0]\n",
    "    frame_width = 720 # Update AUTOMATICALLY!\n",
    "    frame_height = 1280 # Update AUTOMATICALLY!\n",
    "    for i in range(len(data[\"frames\"])):\n",
    "        wrnch_frame = data[\"frames\"][i]\n",
    "        single_frame = []\n",
    "        for single_person_data in wrnch_frame[\"persons\"]:\n",
    "            if (\"pose2d\" not in single_person_data):\n",
    "                continue\n",
    "            if (\"joints\" not in single_person_data[\"pose2d\"]):\n",
    "                continue\n",
    "            arr_2d = single_person_data[\"pose2d\"][\"joints\"]\n",
    "            if (arr_2d == []):\n",
    "                continue\n",
    "            kpts2d = np.array(arr_2d).reshape((25, 2))\n",
    "            kpts2d[:, 0] *= frame_width\n",
    "            kpts2d[:, 1] *= frame_height\n",
    "            kpts2d = np.where(kpts2d < 0, 0, kpts2d)\n",
    "\n",
    "            standard_format = np.hstack((kpts2d[wrnch_to_hrnet], np.ones((17, 1))))\n",
    "            single_frame.append({\n",
    "                \"keypoints\": standard_format\n",
    "            })\n",
    "        standard_format_data.append(single_frame)\n",
    "    \n",
    "    return standard_format_data\n",
    "\n",
    "wrnch_raw_data = get_wrnch_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrnch_raw_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrnch_df = raw_data_to_dataframe(wrnch_raw_data)\n",
    "wrnch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893b12b",
   "metadata": {},
   "source": [
    "# Load Hrnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading pickeled keypoints\n",
    "import pickle\n",
    "with open ('work_dirs/tumeke_testing/pickle_files/AFG_subject_switching_close_nurses_subjects1_partial.p', 'rb') as fp:\n",
    "    raw_data = pickle.load(fp)\n",
    "\n",
    "'''Load picked data into numpy.\n",
    "    \n",
    "Bounding box values are: 'xyxy' = (left, top, right, bottom)\n",
    "\n",
    "Key Point values are: (ndarray[Kx3]): x, y, score\n",
    "\n",
    "'''    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just focus on videos with one subject for now\n",
    "\n",
    "raw_data[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89807934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_shoulder_i = joint_order.index('right_shoulder')\n",
    "# r_elbow_i = joint_order.index('right_elbow')\n",
    "# l_shoulder_i = joint_order.index('left_shoulder')\n",
    "# l_elbow_i = joint_order.index('left_elbow')\n",
    "\n",
    "# keypoint_array = raw_data[2][0]['keypoints']\n",
    "# keypoint_array[r_shoulder_i], keypoint_array[r_elbow_i]\n",
    "# # euclidean_dist(np.array([483.336, 456.679]), np.array([470.485, 504.871])) # 49.876016931988474\n",
    "# euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_elbow_i]) # 49.876083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_shoulder_i = joint_order.index('right_shoulder')\n",
    "# r_elbow_i = joint_order.index('right_elbow')\n",
    "# r_hip_i= joint_order.index('right_hip')\n",
    "# l_shoulder_i = joint_order.index('left_shoulder')\n",
    "# l_elbow_i = joint_order.index('left_elbow')\n",
    "# l_hip_i = joint_order.index('left_hip')\n",
    "\n",
    "# for subject in raw_data[906]:\n",
    "#     print(subject)\n",
    "#     keypoint_array = subject['keypoints']\n",
    "#     r_se_ed = euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_elbow_i])\n",
    "#     r_sh_ed = euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_hip_i])\n",
    "#     l_se_ed = euclidean_dist(keypoint_array[l_shoulder_i], keypoint_array[l_elbow_i])\n",
    "#     l_sh_ed = euclidean_dist(keypoint_array[l_shoulder_i], keypoint_array[l_hip_i])\n",
    "#     print(np.array([r_se_ed, r_sh_ed, l_se_ed, l_sh_ed]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081935ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SORT\n",
    "# sorted_raw_data = []\n",
    "# for frame in raw_data:\n",
    "#     sorted_raw_data.append(sorted(frame, key=lambda x: closest_subject_heuristic(x['keypoints']), reverse=True))\n",
    "    \n",
    "# print(sorted_raw_data[906])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram of subjects per frame\n",
    "# subjects = [len(i) for i in raw_data]\n",
    "# plt.hist(subjects, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "joint_order = [\n",
    "    \"nose\", \n",
    "    \"left_eye\", \n",
    "    \"right_eye\", \n",
    "    \"left_ear\", \n",
    "    \"right_ear\", \n",
    "    \"left_shoulder\", \n",
    "    \"right_shoulder\", \n",
    "    \"left_elbow\", \n",
    "    \"right_elbow\", \n",
    "    \"left_wrist\", \n",
    "    \"right_wrist\", \n",
    "    \"left_hip\", \n",
    "    \"right_hip\", \n",
    "    \"left_knee\", \n",
    "    \"right_knee\", \n",
    "    \"left_ankle\", \n",
    "    \"right_ankle\" \n",
    "]\n",
    "\n",
    "# def index_of(val, in_list):\n",
    "#     try:\n",
    "#         return in_list.index(val)\n",
    "#     except ValueError:\n",
    "#         return -1 \n",
    "\n",
    "# # initializing points in\n",
    "# # numpy arrays\n",
    "# point1 = np.array((1, 2))\n",
    "# point2 = np.array((2, 4))\n",
    " \n",
    "# # calculating Euclidean distance\n",
    "# # using linalg.norm()\n",
    "# dist = np.linalg.norm(point1 - point2)\n",
    "# dist\n",
    "\n",
    "def euclidean_dist(p1, p2):\n",
    "    # Euclidean distance\n",
    "    return np.linalg.norm(p1 - p2)\n",
    "\n",
    "def closest_subject_heuristic(keypoint_array):\n",
    "    '''Get avg euclidean distance between right shoulder/elbow, left shoulder/elbow, right shoulder/hip and left shoulder/hip''' \n",
    "    r_shoulder_i = joint_order.index('right_shoulder')\n",
    "    r_elbow_i = joint_order.index('right_elbow')\n",
    "    r_hip_i= joint_order.index('right_hip')\n",
    "    l_shoulder_i = joint_order.index('left_shoulder')\n",
    "    l_elbow_i = joint_order.index('left_elbow')\n",
    "    l_hip_i = joint_order.index('left_hip')\n",
    "    \n",
    "    r_se_ed = euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_elbow_i])\n",
    "    r_sh_ed = euclidean_dist(keypoint_array[r_shoulder_i], keypoint_array[r_hip_i])\n",
    "    l_se_ed = euclidean_dist(keypoint_array[l_shoulder_i], keypoint_array[l_elbow_i])\n",
    "    l_sh_ed = euclidean_dist(keypoint_array[l_shoulder_i], keypoint_array[l_hip_i])\n",
    "    return np.array([r_se_ed, r_sh_ed, l_se_ed, l_sh_ed]).mean()\n",
    "\n",
    "def pull_from_dict(key, dict):\n",
    "    try:\n",
    "        return dict[key]\n",
    "    except (KeyError, TypeError):\n",
    "        if key == 'bbox':\n",
    "            return np.full(5,np.NaN)\n",
    "        else:\n",
    "            return np.NaN\n",
    "\n",
    "def extract_subject(subject_num, subjects):\n",
    "    try:\n",
    "        return subjects[subject_num-1]\n",
    "    except IndexError:\n",
    "        return None \n",
    "\n",
    "def raw_data_to_dataframe(raw_data):\n",
    "    \"\"\" Load into dataframe\"\"\"\n",
    "    \n",
    "    # Order subjects in each frame by bbox size\n",
    "    sorted_raw_data = []\n",
    "    for frame in raw_data:\n",
    "        sorted_raw_data.append(sorted(frame, key=lambda x: closest_subject_heuristic(x['keypoints']), reverse=True))\n",
    "\n",
    "    # Get first identified subject in every frame\n",
    "    first_subj = np.array([extract_subject(1, i) for i in sorted_raw_data])\n",
    "\n",
    "    # Extract relevant fields to be set as columns\n",
    "    bbox = np.array([pull_from_dict('bbox', i) for i in first_subj])\n",
    "    area = np.array([pull_from_dict('area', i) for i in first_subj])\n",
    "    track_id = np.array([pull_from_dict('track_id', i) for i in first_subj])\n",
    "\n",
    "    # Structure Keypoints\n",
    "    keypoints_array = []\n",
    "    for frame in first_subj:\n",
    "        \n",
    "        #TODO(znoland):sanity check this and make sure no issues!\n",
    "        # Keypoint order! - configs/_base_/datasets/h36m.py\n",
    "        if not frame:\n",
    "            # If no data for subject\n",
    "            frame_keypoints = {}\n",
    "            for index in range(17):\n",
    "                frame_keypoints['j{}_x'.format(index)] = np.NaN\n",
    "                frame_keypoints['j{}_y'.format(index)] = np.NaN\n",
    "                frame_keypoints['j{}_score'.format(index)] = np.NaN\n",
    "                frame_keypoints['j{}_l'.format(index)] = joint_order[index]\n",
    "            keypoints_array.append(frame_keypoints)\n",
    "            \n",
    "        else:\n",
    "            # If data for subject\n",
    "            frame_keypoints = {}\n",
    "            for index, keypoint in enumerate(frame['keypoints']):\n",
    "                frame_keypoints['j{}_x'.format(index)] = keypoint[0]\n",
    "                frame_keypoints['j{}_y'.format(index)] = keypoint[1]\n",
    "                frame_keypoints['j{}_score'.format(index)] = keypoint[2]\n",
    "                frame_keypoints['j{}_l'.format(index)] = joint_order[index]\n",
    "            keypoints_array.append(frame_keypoints)\n",
    "\n",
    "    # Create seperate dataframes (otherwise can't combine as >1-dimensional fields in pandas or numpy)\n",
    "    bbox_s = pd.DataFrame(bbox, columns=['bbox_left', 'bbox_top', 'bbox_right', 'bbox_bottom', 'bbox_score'])\n",
    "    area_s = pd.DataFrame(area, columns=['area'])\n",
    "    track_id_s = pd.DataFrame(track_id, columns=['track_id'])\n",
    "    keypoints_s = pd.DataFrame(keypoints_array)\n",
    "\n",
    "\n",
    "    # Create combined DataFrame\n",
    "    df = pd.concat([bbox_s,area_s,track_id_s,keypoints_s], axis=1)\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename(columns = {'index':'id'})\n",
    "    return df\n",
    "\n",
    "    #TODO(znoland): Set index as a frame number column (e.g. video1_frame_num)\n",
    "    #TODO(znoland): Add column with the name of the video?\n",
    "\n",
    "    \n",
    "df = raw_data_to_dataframe(raw_data)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# # Skip every other row\n",
    "# df = df.iloc[::2, :]\n",
    "# df = df.set_index('id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce4cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471001aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column names\n",
    "score_column_names = ['bbox_score']\n",
    "for i in range(17):\n",
    "    score_column_names.append('j{}_score'.format(i))\n",
    "\n",
    "pd.DataFrame(df[score_column_names].median()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3e6e8",
   "metadata": {},
   "source": [
    "### Visualize Scores - Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde137a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.show()\n",
    "sns.set(rc={'figure.figsize':(21,15)})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "n_rows=3\n",
    "n_cols=6\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols)\n",
    "\n",
    "# Set x axis limit (keep all charts on same axis)\n",
    "for row in axes:\n",
    "    for chart in row:\n",
    "        chart.set_xlim(0,1) \n",
    "\n",
    "for i, column in enumerate(df[score_column_names].columns):\n",
    "    ax = sns.histplot(df[column],ax=axes[i//n_cols,i%n_cols])\n",
    "    if column == 'bbox_score':\n",
    "        ax.set_title('bbox_score')\n",
    "    else: \n",
    "        ax.set_title(joint_order[i-1]) # Currently has bbox as well, so need to offset title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bc27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2d_skeleton_smoothness(df):\n",
    "    ''' Get Euclidean distance '''\n",
    "    \n",
    "    # Build dict to accumulate calcs\n",
    "    dict_2d_smth = {}\n",
    "    for j in range(17):\n",
    "            joint_field = 'j{}_euc_dist'.format(j)\n",
    "            dict_2d_smth[joint_field] = []\n",
    "\n",
    "    # Iterate through rows (Standard shift(-1) can't be used with this calc, so must iterate)\n",
    "    for i in range(len(df)):\n",
    "        for j in range(17):\n",
    "            joint_field_x = 'j{}_x'.format(j)\n",
    "            joint_field_y = 'j{}_y'.format(j)\n",
    "            joint_field_score = 'j{}_score'.format(j)\n",
    "            \n",
    "            #TODO(znoland): return NaN when score below certain amount?\n",
    "            \n",
    "            try:\n",
    "                dict_2d_smth['j{}_euc_dist'.format(j)].append(\n",
    "                    euclidean_dist(\n",
    "                        np.array([df.loc[i, joint_field_x], df.loc[i, joint_field_y]]), \n",
    "                        np.array([df.loc[i+1, joint_field_x], df.loc[i+1, joint_field_y]])\n",
    "                    )\n",
    "                )\n",
    "            except:\n",
    "                print('skiped row {}'.format(i))\n",
    "\n",
    "    return pd.DataFrame(dict_2d_smth)\n",
    "\n",
    "df_2d_smth = f2d_skeleton_smoothness(df)\n",
    "df_2d_smth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median distance between joints and previous frame by joint\n",
    "df_euc_by_joint = pd.DataFrame(df_2d_smth.median()).T\n",
    "df_euc_by_joint.columns = joint_order\n",
    "df_euc_by_joint.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd3bf2",
   "metadata": {},
   "source": [
    "### Visualize Sample Euclidean Distance - Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2645c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.show()\n",
    "sns.set(rc={'figure.figsize':(21,15)})\n",
    "\n",
    "# df_2d_smth.j0_euc_dist.hist()\n",
    "# sns.histplot(df_2d_smth).show()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "n_rows=3\n",
    "n_cols=6\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols)\n",
    "\n",
    "# Set x axis limit (keep all charts on same axis)\n",
    "for row in axes:\n",
    "    for chart in row:\n",
    "        chart.set_xlim(0,df_2d_smth.quantile(0.90).max()) # df_2d_smth.max().max()\n",
    "\n",
    "for i, column in enumerate(df_2d_smth.columns):\n",
    "    ax = sns.histplot(df_2d_smth[column],ax=axes[i//n_cols,i%n_cols])\n",
    "    ax.set_title(joint_order[i]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672c70",
   "metadata": {},
   "source": [
    "## Load example ground truth video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bd624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('work_dirs/tumeke_testing/ground_truth_labels/AFG_subject_switching_close_nurses_subjects1_partial.json') as f:\n",
    "  labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777faf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa422b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(labels[0]['pose-keypoints'])\n",
    "\n",
    "# test['x_px'] = (test['x']) / 100.0 * test['original_width']\n",
    "# test['y_px'] = (test['y']) / 100.0 * test['original_height']\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.pyplot import figure\n",
    "# import matplotlib.image as mpimg \n",
    "# from scipy import ndimage\n",
    "\n",
    "# img = mpimg.imread('work_dirs/tumeke_testing/ground_truth_images/BAR-S_water_ballon/00001274.jpg')\n",
    "# sns.scatterplot(data=test, x=\"x_px\", y=\"y_px\")\n",
    "# # ax.invert_yaxis()\n",
    "# # width_perc = 720 / 1280\n",
    "# # plt.rcParams[\"figure.figsize\"] = (10 * width_perc, 10)\n",
    "# # plt.xlim(0, 720)\n",
    "# # plt.ylim(0, 1280)\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9777cf6a",
   "metadata": {},
   "source": [
    "## Structure ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, id, keypoints (j0_x, j0_y)\n",
    "\n",
    "# 1) loop through each frame\n",
    "# 2) take the first person (wait till we have the relationships)\n",
    "# 3) pivot into dataframe like previous function for ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe632db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795dec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "joint_order = [\n",
    "    'Nose', \n",
    "    'L_Eye', \n",
    "    'R_Eye', \n",
    "    'L_Ear', \n",
    "    'R_Ear', \n",
    "    'L_Shoulder', \n",
    "    'R_Shoulder', \n",
    "    'L_Elbow', \n",
    "    'R_Elbow', \n",
    "    'L_Wrist', \n",
    "    'R_Wrist', \n",
    "    'L_Hip', \n",
    "    'R_Hip', \n",
    "    'L_Knee', \n",
    "    'R_Knee', \n",
    "    'L_Ankle', \n",
    "    'R_Ankle' \n",
    "]\n",
    "\n",
    "def extract_x_and_y(joint):\n",
    "    return np.array([joint['x'], joint['y']])\n",
    "\n",
    "\n",
    "def closest_subject_heuristic_raw(keypoint_obj):\n",
    "    '''Get avg euclidean distance between right shoulder/elbow, left shoulder/elbow, right shoulder/hip and left shoulder/hip''' \n",
    "    r_shoulder_i = joint_order.index('R_Shoulder')\n",
    "    r_elbow_i = joint_order.index('R_Elbow')\n",
    "    r_hip_i= joint_order.index('R_Hip')\n",
    "    l_shoulder_i = joint_order.index('L_Shoulder')\n",
    "    l_elbow_i = joint_order.index('L_Elbow')\n",
    "    l_hip_i = joint_order.index('L_Hip')\n",
    "    \n",
    "    r_se_ed = euclidean_dist(extract_x_and_y(keypoint_obj[r_shoulder_i]), extract_x_and_y(keypoint_obj[r_elbow_i]))\n",
    "    r_sh_ed = euclidean_dist(extract_x_and_y(keypoint_obj[r_shoulder_i]), extract_x_and_y(keypoint_obj[r_hip_i]))\n",
    "    l_se_ed = euclidean_dist(extract_x_and_y(keypoint_obj[l_shoulder_i]), extract_x_and_y(keypoint_obj[l_elbow_i]))\n",
    "    l_sh_ed = euclidean_dist(extract_x_and_y(keypoint_obj[l_shoulder_i]), extract_x_and_y(keypoint_obj[l_hip_i]))\n",
    "    return np.array([r_se_ed, r_sh_ed, l_se_ed, l_sh_ed]).mean()\n",
    "\n",
    "\n",
    "def ground_truth_processing(labels):\n",
    "    '''Tranform ground truth data into data frame\n",
    "\n",
    "        1) Get Subjects\n",
    "\n",
    "        2) Get Keypoints for each subject\n",
    "\n",
    "        3) Order subjects by heuristic\n",
    "\n",
    "    '''\n",
    "\n",
    "    frame_array = []\n",
    "\n",
    "    for label in labels:\n",
    "    #     label = label_r[0]\n",
    "        # label = labels[0:1][0]\n",
    "\n",
    "        row = {}\n",
    "\n",
    "        # Metadata\n",
    "        img_name = re.search(r'(\\d\\d+)', label['data']['img']).group(0)\n",
    "        row['id'] = int(img_name)\n",
    "        row['ls_id'] = label['id']\n",
    "        row['img'] = label['data']['img']\n",
    "        row['subjects'] = []\n",
    "\n",
    "        #Subjects\n",
    "        persons_t = [p for p in label['annotations'][0]['result'] if p['type'] == 'rectanglelabels']\n",
    "\n",
    "        # Keypoints\n",
    "        keypoints_t = [k for k in label['annotations'][0]['result'] if k['type'] == 'keypointlabels']\n",
    "\n",
    "        for i, person in enumerate(persons_t):\n",
    "\n",
    "            # Filter on subject's keypoints\n",
    "            person_keypoints_t = [k for k in keypoints_t if k['parentID'] == person['id']]\n",
    "            # Filter out unused keypoints\n",
    "            person_keypoints_t = [k for k in person_keypoints_t if k['value']['keypointlabels'][0] in joint_order]\n",
    "\n",
    "             # Set order of keypoints + set placeholders when null\n",
    "            person_keypoints_sorted = []\n",
    "            for i, joint_name in enumerate(joint_order):\n",
    "                target_keypoint = [k for k in person_keypoints_t if k['value']['keypointlabels'][0] == joint_name]\n",
    "\n",
    "                if target_keypoint:\n",
    "                    original_width = target_keypoint[0]['original_width']\n",
    "                    original_height = target_keypoint[0]['original_height']\n",
    "                    target_keypoint = target_keypoint[0]['value']\n",
    "                    target_keypoint['original_width'] = original_width\n",
    "                    target_keypoint['original_height'] = original_height\n",
    "                else:\n",
    "                    target_keypoint = {'x': np.nan, 'y': np.nan, 'width': np.nan, 'keypointlabels': [joint_name], 'original_width': np.nan, 'original_height': np.nan, }\n",
    "\n",
    "                person_keypoints_sorted.append(target_keypoint)\n",
    "\n",
    "            subject_t = {\n",
    "                'name': person['value']['rectanglelabels'][0],\n",
    "                'id': person['id'],\n",
    "                'pose-keypoints': person_keypoints_sorted,\n",
    "                'closest-subject-heuristic': closest_subject_heuristic_raw(person_keypoints_sorted)\n",
    "            }\n",
    "            row['subjects'].append(subject_t)\n",
    "\n",
    "\n",
    "        # Sort subjects by heuristic\n",
    "        row['subjects'] = sorted(row['subjects'], key=lambda x: x['closest-subject-heuristic'], reverse=True)\n",
    "\n",
    "        # Format x & y coordinates (for 1st subject only)\n",
    "        for index, keypoint in enumerate(row['subjects'][0]['pose-keypoints']):\n",
    "            if len(keypoint['keypointlabels']) > 1:\n",
    "                raise ValueError('There are multiple labels for one keypoint!') \n",
    "            row['j{}_x'.format(index)] = keypoint['x'] / 100.0 * keypoint['original_width']\n",
    "            row['j{}_y'.format(index)] = keypoint['y'] / 100.0 * keypoint['original_height']\n",
    "            row['j{}_l'.format(index)] = keypoint['keypointlabels'][0]\n",
    "\n",
    "        frame_array.append(row)\n",
    "        \n",
    "    return frame_array\n",
    "\n",
    "# raw array is \"frame_array\" !\n",
    "gt_frame_array = ground_truth_processing(labels)\n",
    "gt_df = pd.DataFrame(gt_frame_array)\n",
    "# Order by ID\n",
    "gt_df = gt_df.sort_values(by='id')\n",
    "gt_df = gt_df.reset_index(drop=True)\n",
    "gt_df = gt_df.set_index('id')\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df['subjects'].loc[[2]].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd03b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf23b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLDER METHOD FOR SIGNLE SUBJECT VIDEOS\n",
    "\n",
    "# import re\n",
    "\n",
    "# joint_order = [\n",
    "#     'Nose', \n",
    "#     'L_Eye', \n",
    "#     'R_Eye', \n",
    "#     'L_Ear', \n",
    "#     'R_Ear', \n",
    "#     'L_Shoulder', \n",
    "#     'R_Shoulder', \n",
    "#     'L_Elbow', \n",
    "#     'R_Elbow', \n",
    "#     'L_Wrist', \n",
    "#     'R_Wrist', \n",
    "#     'L_Hip', \n",
    "#     'R_Hip', \n",
    "#     'L_Knee', \n",
    "#     'R_Knee', \n",
    "#     'L_Ankle', \n",
    "#     'R_Ankle' \n",
    "# ]\n",
    "\n",
    "# def ground_truth_etl(labels):\n",
    "#     '''Tranform ground truth data into data frame'''\n",
    "#     frame_array = []\n",
    "#     for label in labels:\n",
    "#         row = {}\n",
    "#         img_name = re.search(r'(\\d\\d+)', label['img']).group(0)\n",
    "#         row['id'] = int(img_name)\n",
    "#         row['ls_id'] = label['id']\n",
    "#         row['img'] = label['img']\n",
    "        \n",
    "#         # Filter out unused keypoints\n",
    "#         label['pose-keypoints'] = [keypoint for keypoint in label['pose-keypoints'] if keypoint['keypointlabels'][0] in joint_order]\n",
    "#         # Set order of keypoints\n",
    "#         label['pose-keypoints'].sort(key=lambda x: joint_order.index(x['keypointlabels'][0]))\n",
    "\n",
    "#         for index, keypoint in enumerate(label['pose-keypoints']):\n",
    "#             if len(keypoint['keypointlabels']) > 1:\n",
    "#                 raise ValueError('There are multiple labels for one keypoint!') \n",
    "#             row['j{}_x'.format(index)] = keypoint['x'] / 100.0 * keypoint['original_width']\n",
    "#             row['j{}_y'.format(index)] = keypoint['y'] / 100.0 * keypoint['original_height']\n",
    "#             row['j{}_l'.format(index)] = keypoint['keypointlabels'][0]\n",
    "\n",
    "#         frame_array.append(row)\n",
    "        \n",
    "#     return pd.DataFrame(frame_array)\n",
    "        \n",
    "# gt_df = ground_truth_etl(labels)\n",
    "# # Order by ID\n",
    "# gt_df = gt_df.sort_values(by='id')\n",
    "# gt_df = gt_df.reset_index(drop=True)\n",
    "# gt_df = gt_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: IT APPEARS AS IF A ROW IS NOT RETURNED WHEN a frame is not labeled!!!\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.image as mpimg \n",
    "from scipy import ndimage\n",
    "import re\n",
    "\n",
    "def visualize_gt_frame(frame_row):\n",
    "    img_name = re.search(r'(\\d+[.][jpg]+)', frame_row['img'].values[0]).group(0)\n",
    "    img = mpimg.imread('work_dirs/tumeke_testing/ground_truth_images/BAR-S_water_ballon/{}'.format(img_name))\n",
    "    for j in range(17): # 19 originally\n",
    "        x = \"j{}_x\".format(j)\n",
    "        y = \"j{}_y\".format(j)\n",
    "        l = \"j{}_l\".format(j)\n",
    "        p1 = sns.scatterplot(data=frame_row, x=x, y=y)\n",
    "        # Add text besides each point\n",
    "        p1.text(frame_row[x]+10, frame_row[y], \n",
    "             frame_row[l].values[0], horizontalalignment='left', \n",
    "             size=7, color='white', weight='regular')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177eecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_gt_frame(gt_df[0:1])\n",
    "# visualize_gt_frame(gt_df[20:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532491d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_df[0:1].img.values[0] # 1 indexed - The frame number is the image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ff8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_overlap(frame_number):\n",
    "    gt_f = gt_df.loc[[frame_number]]\n",
    "    f = df.loc[[frame_number]]\n",
    "    w_f = wrnch_df.loc[[frame_number]]\n",
    "    \n",
    "    frame_img_name = re.search(r'(\\d+[.][jpg]+)', gt_f['img'].values[0]).group(0)\n",
    "    file_img_name = re.findall(r'/([0-9a-zA-Z-_]+)', gt_df[0:1].img.values[0])[1]\n",
    "    img = mpimg.imread('work_dirs/tumeke_testing/ground_truth_images/{}/{}'.format(file_img_name, frame_img_name))\n",
    "    \n",
    "    for j in range(17):\n",
    "        x = \"j{}_x\".format(j)\n",
    "        y = \"j{}_y\".format(j)\n",
    "        l = \"j{}_l\".format(j)\n",
    "        # Ground Truth - BLUE\n",
    "        p1 = sns.scatterplot(data=gt_f, x=x, y=y, color='blue')\n",
    "        p1.text(gt_f[x]-70, gt_f[y], \n",
    "             gt_f[l].values[0], horizontalalignment='left', \n",
    "             size=7, color='blue', weight='regular')\n",
    "        # Hrnet Model - RED\n",
    "        p2 = sns.scatterplot(data=f, x=x, y=y, color='red')\n",
    "        p2.text(f[x]+20, f[y]-1, \n",
    "             f[l].values[0], horizontalalignment='left', \n",
    "             size=7, color='red', weight='regular')\n",
    "        \n",
    "        # Wrnch - GREEN\n",
    "        p3 = sns.scatterplot(data=w_f, x=x, y=y, color='green')\n",
    "        p3.text(w_f[x]+20, w_f[y]+1, \n",
    "             w_f[l].values[0], horizontalalignment='left', \n",
    "             size=7, color='green', weight='regular')\n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "visualize_overlap(1000) # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e63596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = df['j0_x'] / gt_df['j0_x']\n",
    "# test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4561bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[[600]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0dae2",
   "metadata": {},
   "source": [
    "## PCK - Percentage of Correct Key-points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a5f96",
   "metadata": {},
   "source": [
    "Description: https://github.com/cbsudux/Human-Pose-Estimation-101#percentage-of-correct-parts---pcp\n",
    "\n",
    "\n",
    "Percentage of Correct Key-points - PCK:\n",
    "* Detected joint is considered correct if the distance between the predicted and the true joint is within a certain threshold (threshold varies)\n",
    "* PCKh@0.5 is when the threshold = 50% of the head bone link\n",
    "* PCK@0.2 == Distance between predicted and true joint < 0.2 * torso diameter\n",
    "* Sometimes 150 mm is taken as the threshold\n",
    "* Head, shoulder, Elbow, Wrist, Hip, Knee, Ankle  Keypoints\n",
    "* PCK is used for 2D and 3D (PCK3D)\n",
    "* Higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pelvis is in the middle of l_hip and r_hip\n",
    "# keypoints_new[0] = (keypoints[11] + keypoints[12]) / 2\n",
    "# thorax is in the middle of l_shoulder and r_shoulder\n",
    "# keypoints_new[8] = (keypoints[5] + keypoints[6]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae130487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT !!!!!!!!!!! - THIS IS A TEST - CHANGE BACK!\n",
    "# df = wrnch_df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae80134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_j_pos(f, v, joint_name):\n",
    "    return f['j{}_{}'.format(joint_order.index(joint_name), v)]\n",
    "\n",
    "def get_torso_diameter(x):\n",
    "    return euclidean_dist(np.array([x['pelvis_x'], x['pelvis_y']]), np.array([x['thorax_x'], x['thorax_y']]))\n",
    "\n",
    "for df_i in [df, gt_df]:\n",
    "    \n",
    "    df_i['pelvis_x'] = (extract_j_pos(df_i, 'x', 'L_Hip') + extract_j_pos(df_i, 'x', 'R_Hip')) / 2\n",
    "    df_i['pelvis_y'] = (extract_j_pos(df_i, 'y', 'L_Hip') + extract_j_pos(df_i, 'y', 'R_Hip')) / 2\n",
    "    df_i['thorax_x'] = (extract_j_pos(df_i, 'x', 'L_Shoulder') + extract_j_pos(df_i, 'x', 'R_Shoulder')) / 2\n",
    "    df_i['thorax_y'] = (extract_j_pos(df_i, 'y', 'L_Shoulder') + extract_j_pos(df_i, 'y', 'R_Shoulder')) / 2\n",
    "    \n",
    "    df_i['torso_diameter'] = df_i.apply(lambda x: get_torso_diameter(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Iterate through keypoints and check \n",
    "#    - distance between predicted and true joint < 0.2 * torso diameter\n",
    "\n",
    "# 2) for row, get jX_d (joint detected)\n",
    "\n",
    "# 3) Get percent of all values detected (across all keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "pck_threshold_s = .20 * gt_df['torso_diameter']\n",
    "pck_threshold_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_duclidean_dist(df1, df2, cols=['x_coord','y_coord']):\n",
    "    return np.linalg.norm(df1[cols].values - df2[cols].values, axis=1)\n",
    "\n",
    "pck_df_raw = gt_df[[]] # Return just index\n",
    "for j in range(17):\n",
    "    x = \"j{}_x\".format(j)\n",
    "    y = \"j{}_y\".format(j)\n",
    "    pck_df_raw['{}_ed'.format(joint_order[j])] = vect_duclidean_dist(gt_df, df.iloc[gt_df.index], cols=[x,y])\n",
    "    # pck_df['{}'.format(joint_order[j])] = vec_euclidean_dist(gt_df[[x,y]], df.iloc[gt_df.index][[x,y]])\n",
    "\n",
    "pck_df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pck_df_scores = pck_df_raw.lt(pck_threshold_s, axis='index') # True if distance less than PCK threshold\n",
    "pck_df_scores = pck_df_scores.applymap(lambda x: 1 if x == True else 0)\n",
    "pck_df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Detected frames\n",
    "pck_df_scores.sum(axis=1).apply(lambda x: 1 if x > 0 else 0).sum() / pck_df_scores.sum(axis=1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total (all frames)\n",
    "pck_df_scores.sum(axis=1).sum() / pck_df_scores.count(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total (detected frames)\n",
    "pck_detected_df = pck_df_scores.sum(axis=1).apply(lambda x: True if x > 0 else False)\n",
    "pck_df_scores[pck_detected_df].sum(axis=1).sum() / pck_df_scores[pck_detected_df].count(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96367f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Body part\n",
    "pck_df_scores.sum() / pck_df_scores.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by frame\n",
    "# pd.DataFrame(pck_df_scores.sum(axis=1) / pck_df_scores.count(axis=1), columns=['PCK']).plot.area()\n",
    "pd.DataFrame(pck_df_scores).plot.area(title='PCK over time by joint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10801765",
   "metadata": {},
   "source": [
    "## PCP - Percentage of Correct Parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4502aef",
   "metadata": {},
   "source": [
    "https://github.com/cbsudux/Human-Pose-Estimation-101#percentage-of-correct-parts---pcp\n",
    "\n",
    "### Percentage of Correct Parts - PCP\n",
    "* A limb is considered detected and a correct part if the distance between the two predicted joint locations and the true limb joint locations is at most half of the limb length (PCP at 0.5 )\n",
    "* Measures detection rate of limbs\n",
    "* Cons - penalizes shorter limbs\n",
    "\n",
    "Calculation:\n",
    "* For a specific part, PCP = (No. of correct parts for entire dataset) / (No. of total parts for entire dataset)\n",
    "* Take a dataset with 10 images and 1 pose per image. Each pose has 8 parts - ( upper arm, lower arm, upper leg, lower leg ) x2\n",
    "* No of upper arms = 10 * 2 = 20\n",
    "* No of lower arms = 20\n",
    "* No of lower legs = No of upper legs = 20\n",
    "* If upper arm is detected correct for 17 out of the 20 upper arms i.e 17 ( 10 right arms and 7 left)  PCP = 17/20 = 85%\n",
    "\n",
    "Higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) ground truth limb length\n",
    "\n",
    "# 2) Euclidean distance between joints (already done) + avg between start joint and end joint euclidean distances\n",
    "\n",
    "# 3) Check if limb ed is less than threshold (ground truth limb length * .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b89238",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ground Truth Limb Length'''\n",
    "limbs = [\n",
    "    {'name':'L_upper_arm', 'joints': [joint_order.index('L_Shoulder'), joint_order.index('L_Elbow')]},\n",
    "    {'name':'R_upper_arm', 'joints': [joint_order.index('R_Shoulder'), joint_order.index('R_Elbow')]},\n",
    "    {'name':'L_lower_arm', 'joints': [joint_order.index('L_Elbow'), joint_order.index('L_Wrist')]},\n",
    "    {'name':'R_lower_arm', 'joints': [joint_order.index('R_Elbow'), joint_order.index('R_Wrist')]},\n",
    "    {'name':'L_upper_leg', 'joints': [joint_order.index('L_Hip'), joint_order.index('L_Knee')]},\n",
    "    {'name':'R_upper_leg', 'joints': [joint_order.index('R_Hip'), joint_order.index('R_Knee')]},\n",
    "    {'name':'L_lower_leg', 'joints': [joint_order.index('L_Knee'), joint_order.index('L_Ankle')]},\n",
    "    {'name':'R_lower_leg', 'joints': [joint_order.index('R_Knee'), joint_order.index('R_Ankle')]}\n",
    "]\n",
    "\n",
    "# def get_limb_diameter(r):\n",
    "#     return euclidean_dist(np.array([r[x1], r[y1]]), np.array([r[x2], r[y2]]))\n",
    "\n",
    "pcp_gt_limb_length_df = gt_df[[]] # Return just index\n",
    "for limb in limbs:\n",
    "    # Get ground truth limb length\n",
    "    j1 = limb['joints'][0] # joint 1 index\n",
    "    j2 = limb['joints'][1] # joint 2 index\n",
    "    x1 = \"j{}_x\".format(j1)\n",
    "    y1 = \"j{}_y\".format(j1)\n",
    "    x2 = \"j{}_x\".format(j2)\n",
    "    y2 = \"j{}_y\".format(j2)\n",
    "    pcp_gt_limb_length_df[limb['name']] = gt_df.apply(lambda r: euclidean_dist(np.array([r[x1], r[y1]]), np.array([r[x2], r[y2]])), axis=1)\n",
    "\n",
    "pcp_gt_limb_length_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad552c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PCP Theshold'''\n",
    "pcp_threshold_df = pcp_gt_limb_length_df * 0.50\n",
    "pcp_threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00693586",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Limb Euclidean Dist'''\n",
    "limbs = [\n",
    "    {'name':'L_upper_arm', 'joints': ['L_Shoulder', 'L_Elbow']},\n",
    "    {'name':'R_upper_arm', 'joints': ['R_Shoulder', 'R_Elbow']},\n",
    "    {'name':'L_lower_arm', 'joints': ['L_Elbow', 'L_Wrist']},\n",
    "    {'name':'R_lower_arm', 'joints': ['R_Elbow', 'R_Wrist']},\n",
    "    {'name':'L_upper_leg', 'joints': ['L_Hip', 'L_Knee']},\n",
    "    {'name':'R_upper_leg', 'joints': ['R_Hip', 'R_Knee']},\n",
    "    {'name':'L_lower_leg', 'joints': ['L_Knee', 'L_Ankle']},\n",
    "    {'name':'R_lower_leg', 'joints': ['R_Knee', 'R_Ankle']}\n",
    "]\n",
    "\n",
    "pcp_limb_ed_df = gt_df[[]] # Return just index\n",
    "for limb in limbs:\n",
    "    j1 = limb['joints'][0] # joint 1 name\n",
    "    j2 = limb['joints'][1] # joint 2 name\n",
    "    \n",
    "    pcp_limb_ed_df[limb['name']] = pck_df_raw['{}_ed'.format(j1)] + pck_df_raw['{}_ed'.format(j2)] / 2\n",
    "    \n",
    "pcp_limb_ed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcp_df_scores = pck_df_raw.lt(pck_threshold_s, axis='index') # True if distance less than PCP threshold\n",
    "# pcp_df_scores = pck_df_scores.applymap(lambda x: 1 if x == True else 0)\n",
    "# pcp_df_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_df_scores = pcp_limb_ed_df.lt(pcp_threshold_df)\n",
    "pcp_df_scores = pcp_df_scores.applymap(lambda x: 1 if x == True else 0)\n",
    "pcp_df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Detected frames\n",
    "pcp_df_scores.sum(axis=1).apply(lambda x: 1 if x > 0 else 0).sum() / pcp_df_scores.sum(axis=1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04947419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total (all frames)\n",
    "pcp_df_scores.sum(axis=1).sum() / pcp_df_scores.count(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4befd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total (detected frames)\n",
    "pcp_detected_df = pcp_df_scores.sum(axis=1).apply(lambda x: True if x > 0 else False)\n",
    "pcp_df_scores[pcp_detected_df].sum(axis=1).sum() / pcp_df_scores[pcp_detected_df].count(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d056a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Limb\n",
    "pcp_df_scores.sum() / pcp_df_scores.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ef3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by Frame\n",
    "pd.DataFrame(pcp_df_scores).plot.area(title='PCP over time by limb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb217a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update summary calcs!:\n",
    "# 1) For frames where there is an output, how accurate is that output? (if entire row = 0, then exclude row in calculation)\n",
    "# 2) Calculate number of detected frames (rows that have at least 1 value in threshold (row > 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ef9df",
   "metadata": {},
   "source": [
    "# Tests with Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fe1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tumeke_testing_modules import load_model_data, load_gt_data\n",
    "# from tumeke_testing_modules.visualize_frame import visualize_overlap\n",
    "# from tumeke_testing_modules.pck_calc import pck_calc\n",
    "# from tumeke_testing_modules.pcp_calc import pcp_calc\n",
    "# from tumeke_testing_modules.visualize_df_scores import visualize_df_scores\n",
    "# from tumeke_testing_modules.smoothness_calc import smoothness_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2364f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # file = 'AFG_subject_switching_close_nurses_subjects1_partial'\n",
    "# file = 'BAR-S_water_ballon_trimmed' # Need to export full annotation file, not partial\n",
    "\n",
    "# hrnet_df, wrnch_df = load_model_data.get_hrnet_wrnch_dfs(file)\n",
    "# gt_df = load_gt_data.get_gt_df(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_df_scores(hrnet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25246e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pck_calc(gt_df, hrnet_df, wrnch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_overlap(gt_df, hrnet_df, wrnch_df, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d26135",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pcp_calc(gt_df, hrnet_df, wrnch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52508f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# smoothness_calc(gt_df, hrnet_df, wrnch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b976c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29107f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2305c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
